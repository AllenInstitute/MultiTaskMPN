{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374fb8f2-9b83-44ce-821b-8917a114c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "import copy \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# PyTorch Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data Handling and Image Processing\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Style for Matplotlib\n",
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.style.use(['no-latex'])\n",
    "\n",
    "# Scientific Computing and Machine Learning\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.linalg import subspace_angles\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Custom Modules and Extensions\n",
    "sys.path.append(\"../netrep/\")\n",
    "sys.path.append(\"../svcca/\")\n",
    "import cca_core\n",
    "from netrep.metrics import LinearMetric\n",
    "import networks as nets  # Contains RNNs\n",
    "import net_helpers\n",
    "import mpn_tasks\n",
    "import helper\n",
    "import mpn\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.style.use(['no-latex'])\n",
    "\n",
    "# Memory Optimization\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1556c8-a4b6-434b-a60f-37035980bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 Red, 1 blue, 2 green, 3 purple, 4 orange, 5 teal, 6 gray, 7 pink, 8 yellow\n",
    "c_vals = ['#e53e3e', '#3182ce', '#38a169', '#805ad5','#dd6b20', '#319795', '#718096', '#d53f8c', '#d69e2e',] * 10\n",
    "c_vals_l = ['#feb2b2', '#90cdf4', '#9ae6b4', '#d6bcfa', '#fbd38d', '#81e6d9', '#e2e8f0', '#fbb6ce', '#faf089',] * 10\n",
    "c_vals_d = ['#9b2c2c', '#2c5282', '#276749', '#553c9a', '#9c4221', '#285e61', '#2d3748', '#97266d', '#975a16',] * 10 \n",
    "l_vals = ['solid', 'dashed', 'dotted', 'dashdot', '-', '--', '-.', ':', (0, (3, 1, 1, 1)), (0, (5, 10))]\n",
    "markers_vals = ['o', 'v', '*', '+', '>', '1', '2', '3', '4', 's', 'p', '*', 'h', 'H', '+', 'x', 'D', 'd', '|', '_']\n",
    "linestyles = [\"-\", \"--\", \"-.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d36397-6fe4-4124-bf57-307f571e9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34978bf6-67b8-41bd-a022-a7b46a320686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set seed 195\n",
      "Fixation_off: True; Task_info: True\n",
      "Rules: ['delaydm1', 'delaydm2', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm']\n",
      "  Input size 11, Output size 3\n",
      "Using CUDA...\n"
     ]
    }
   ],
   "source": [
    "# Reload modules if changes have been made to them\n",
    "from importlib import reload\n",
    "\n",
    "reload(nets)\n",
    "reload(net_helpers)\n",
    "\n",
    "fixseed = False # randomize setting the seed may lead to not perfectly solved results\n",
    "seed = random.randint(1,1000) if not fixseed else 8 # random set the seed to test robustness by default\n",
    "print(f\"Set seed {seed}\")\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "hyp_dict['task_type'] = 'multitask' # int, NeuroGym, multitask\n",
    "hyp_dict['mode_for_all'] = \"random_batch\"\n",
    "hyp_dict['ruleset'] = 'dm_family' # low_dim, all, test\n",
    "\n",
    "accept_rules = ('fdgo', 'fdanti', 'delaygo', 'delayanti', 'reactgo', 'reactanti', \n",
    "                'delaydm1', 'delaydm2', 'dmsgo', 'dmcgo', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm')\n",
    "\n",
    "\n",
    "rules_dict = \\\n",
    "    {'all' : ['fdgo', 'reactgo', 'delaygo', 'fdanti', 'reactanti', 'delayanti',\n",
    "              'dm1', 'dm2', 'contextdm1', 'contextdm2', 'multidm',\n",
    "              'delaydm1', 'delaydm2', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm',\n",
    "              'dmsgo', 'dmsnogo', 'dmcgo', 'dmcnogo'],\n",
    "     'low_dim' : ['fdgo', 'reactgo', 'delaygo', 'fdanti', 'reactanti', 'delayanti',\n",
    "                 'delaydm1', 'delaydm2', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm',\n",
    "                 'dmsgo', 'dmsnogo', 'dmcgo', 'dmcnogo'],\n",
    "     'delayfamily': ['delaygo', 'delayanti'], \n",
    "     'simplegofamily': ['fdgo', 'fdanti', 'reactgo', 'reactanti'],\n",
    "     'gofamily': ['fdgo', 'fdanti', 'reactgo', 'reactanti', 'delaygo', 'delayanti'],\n",
    "     'gofamily_delaydm': ['fdgo', 'fdanti', 'reactgo', 'reactanti', 'delaygo', 'delayanti', 'delaydm1', 'delaydm2'],\n",
    "     'dm_family': ['delaydm1', 'delaydm2', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm']\n",
    "    }\n",
    "    \n",
    "\n",
    "# This can either be used to set parameters OR set parameters and train\n",
    "train = True # whether or not to train the network\n",
    "verbose = True\n",
    "hyp_dict['run_mode'] = 'minimal' # minimal, debug\n",
    "hyp_dict['chosen_network'] = \"dmpn\"\n",
    "\n",
    "# suffix for saving images\n",
    "# inputadd, Wfix, WL2, hL2\n",
    "# inputrandom, Wtrain\n",
    "# noise001\n",
    "# largeregularization\n",
    "# trainetalambda\n",
    "\n",
    "mpn_depth = 1\n",
    "n_hidden = 150\n",
    "\n",
    "hyp_dict['addon_name'] = \"inputrandom+Wtrain+WL2+hL2+etamatrix\"\n",
    "hyp_dict['addon_name'] += f\"+hidden{n_hidden}\"\n",
    "\n",
    "# for coding \n",
    "if hyp_dict['chosen_network'] in (\"gru\", \"vanilla\"):\n",
    "    mpn_depth = 1\n",
    "\n",
    "def current_basic_params():\n",
    "    task_params = {\n",
    "        'task_type': hyp_dict['task_type'],\n",
    "        'rules': rules_dict[hyp_dict['ruleset']],\n",
    "        'dt': 40, # ms, directly influence sequence lengths,\n",
    "        'ruleset': hyp_dict['ruleset'],\n",
    "        'n_eachring': 8, # Number of distinct possible inputs on each ring\n",
    "        'in_out_mode': 'low_dim',  # high_dim or low_dim or low_dim_pos (Robert vs. Laura's paper, resp)\n",
    "        'sigma_x': 0.00, # Laura raised to 0.1 to prevent overfitting (Robert uses 0.01)\n",
    "        'mask_type': 'cost', # 'cost', None\n",
    "        'fixate_off': True, # Second fixation signal goes on when first is off\n",
    "        'task_info': True, \n",
    "        'randomize_inputs': False,\n",
    "        'n_input': 20, # Only used if inputs are randomized,\n",
    "        'modality_diff': True,\n",
    "        'label_strength': True, \n",
    "        'long_delay': 'normal' \n",
    "    }\n",
    "\n",
    "    print(f\"Fixation_off: {task_params['fixate_off']}; Task_info: {task_params['task_info']}\")\n",
    "\n",
    "    train_params = {\n",
    "        'lr': 1e-3,\n",
    "        'n_batches': 256,\n",
    "        'batch_size': 256,\n",
    "        'gradient_clip': 10,\n",
    "        'valid_n_batch': 30,\n",
    "        'n_datasets': 300, \n",
    "        'n_epochs_per_set': 200, \n",
    "        'weight_reg': 'L2',\n",
    "        'activity_reg': 'L2', \n",
    "        'reg_lambda': 1e-4,\n",
    "        \n",
    "        'scheduler': {\n",
    "            'type': 'ReduceLROnPlateau',  # or 'StepLR'\n",
    "            'mode': 'min',                # for ReduceLROnPlateau\n",
    "            'factor': 0.5,                # factor to reduce LR\n",
    "            'patience': 10,                # epochs to wait before reducing LR\n",
    "            'step_size': 30,              # for StepLR (step every 30 datasets)\n",
    "            'gamma': 0.1                  # for StepLR (multiply LR by 0.1)\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if not train: # some \n",
    "        assert train_params['n_epochs_per_set'] == 0\n",
    "\n",
    "    net_params = {\n",
    "        'net_type': hyp_dict['chosen_network'], # mpn1, dmpn, vanilla\n",
    "        'n_neurons': [1] + [n_hidden] * mpn_depth + [1],\n",
    "        'output_bias': False, # Turn off biases for easier interpretation\n",
    "        'loss_type': 'MSE', # XE, MSE\n",
    "        'activation': 'tanh', # linear, ReLU, sigmoid, tanh, tanh_re, tukey, heaviside\n",
    "        'cuda': True,\n",
    "        'monitor_freq': 100,\n",
    "        'monitor_valid_out': True, # Whether or not to save validation output throughout training\n",
    "        'output_matrix': '',# \"\" (default); \"untrained\", or \"orthogonal\"\n",
    "        'input_layer_add': True, \n",
    "        'input_layer_add_trainable': True, # revise this is effectively to [randomize_inputs], tune this\n",
    "        'input_layer_bias': False, \n",
    "        'input_layer': \"trainable\", # for RNN only\n",
    "        \n",
    "        # for one-layer MPN, GRU or Vanilla\n",
    "        'ml_params': {\n",
    "            'bias': True, # Bias of layer\n",
    "            'mp_type': 'mult',\n",
    "            'm_update_type': 'hebb_assoc', # hebb_assoc, hebb_pre\n",
    "            'eta_type': 'scalar', # scalar, pre_vector, post_vector, matrix\n",
    "            'eta_train': True,\n",
    "            # 'eta_init': 'mirror_gaussian', #0.0,\n",
    "            'lam_type': 'scalar', # scalar, pre_vector, post_vector, matrix\n",
    "            'm_time_scale': 4000, # ms, sets lambda\n",
    "            'lam_train': False,\n",
    "            'W_freeze': False, # different combination with [input_layer_add_trainable]\n",
    "        },\n",
    "\n",
    "        # Vanilla RNN params\n",
    "        'leaky': True,\n",
    "        'alpha': 0.2,\n",
    "    }\n",
    "\n",
    "    # Ensure the two options are *not* activated at the same time\n",
    "    assert not (task_params[\"randomize_inputs\"] and net_params[\"input_layer_add\"]), (\n",
    "        \"task_params['randomize_inputs'] and net_params['input_layer_add'] cannot both be True.\"\n",
    "    )\n",
    "\n",
    "    # for multiple MPN layers, assert \n",
    "    if mpn_depth > 1:\n",
    "        for mpl_idx in range(mpn_depth - 1):\n",
    "            assert f'ml_params{mpl_idx}' in net_params.keys()\n",
    "\n",
    "    # actually I don't think it is needed\n",
    "    # putting here to warn the parameter checking every time \n",
    "    # when switching network\n",
    "    if hyp_dict['chosen_network'] in (\"gru\", \"vanilla\"):\n",
    "        assert f'ml_params' in net_params.keys()\n",
    "\n",
    "    return task_params, train_params, net_params\n",
    "\n",
    "task_params, train_params, net_params = current_basic_params()\n",
    "\n",
    "shift_index = 1 if not task_params['fixate_off'] else 0\n",
    "\n",
    "if hyp_dict['task_type'] in ('multitask',):\n",
    "    task_params, train_params, net_params = mpn_tasks.convert_and_init_multitask_params(\n",
    "        (task_params, train_params, net_params)\n",
    "    )\n",
    "\n",
    "    net_params['prefs'] = mpn_tasks.get_prefs(task_params['hp'])\n",
    "\n",
    "    print('Rules: {}'.format(task_params['rules']))\n",
    "    print('  Input size {}, Output size {}'.format(\n",
    "        task_params['n_input'], task_params['n_output'],\n",
    "    ))\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "if net_params['cuda']:\n",
    "    print('Using CUDA...')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('Using CPU...')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# how many epoch each dataset will be trained on\n",
    "epoch_multiply = train_params[\"n_epochs_per_set\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a341b36-dc7a-42b0-bffb-cb17d380041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = task_params, train_params, net_params\n",
    "\n",
    "if net_params['net_type'] == 'mpn1':\n",
    "    netFunction = mpn.MultiPlasticNet\n",
    "elif net_params['net_type'] == 'dmpn':\n",
    "    netFunction = mpn.DeepMultiPlasticNet\n",
    "elif net_params['net_type'] == 'vanilla':\n",
    "    netFunction = nets.VanillaRNN\n",
    "elif net_params['net_type'] == 'gru':\n",
    "    netFunction = nets.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e4fe48-2af6-4741-8d42-01803ba0abf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align ['delaydm1', 'delaydm2', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm'] With Same Time\n",
      "delaydm1\n",
      "delaydm2\n",
      "contextdelaydm1\n",
      "contextdelaydm2\n",
      "multidelaydm\n",
      "{'delaydm1': {'fix1': (None, 10), 'stim1': (10, 25), 'delay1': (25, 45), 'stim2': (45, 55), 'delay2': (55, 59), 'go1': (59, 71)}, 'delaydm2': {'fix1': (None, 10), 'stim1': (10, 20), 'delay1': (20, 40), 'stim2': (40, 55), 'delay2': (55, 60), 'go1': (60, 72)}, 'contextdelaydm1': {'fix1': (None, 10), 'stim1': (10, 20), 'delay1': (20, 40), 'stim2': (40, 45), 'delay2': (45, 48), 'go1': (48, None)}, 'contextdelaydm2': {'fix1': (None, 5), 'stim1': (5, 10), 'delay1': (10, 15), 'stim2': (15, 25), 'delay2': (25, 32), 'go1': (32, None)}, 'multidelaydm': {'fix1': (None, 10), 'stim1': (10, 20), 'delay1': (20, 40), 'stim2': (40, 55), 'delay2': (55, 61), 'go1': (61, None)}}\n"
     ]
    }
   ],
   "source": [
    "test_n_batch = train_params[\"valid_n_batch\"]\n",
    "color_by = \"stim\" # or \"resp\" \n",
    "\n",
    "task_random_fix = True\n",
    "if task_random_fix:\n",
    "    print(f\"Align {task_params['rules']} With Same Time\")\n",
    "\n",
    "if task_params['task_type'] in ('multitask',): # Test batch consists of all the rules\n",
    "    task_params['hp']['batch_size_train'] = test_n_batch\n",
    "    # using homogeneous cutting off\n",
    "    test_mode_for_all = \"random\"\n",
    "    # ZIHAN\n",
    "    # generate test data using \"random\"\n",
    "    test_data, test_trials_extra = mpn_tasks.generate_trials_wrap(task_params, test_n_batch, \\\n",
    "                rules=task_params['rules'], mode_input=test_mode_for_all, fix=task_random_fix\n",
    "    )\n",
    "    _, test_trials, test_rule_idxs = test_trials_extra\n",
    "    task_params['dataset_name'] = 'multitask'\n",
    "\n",
    "    if task_params['in_out_mode'] in ('low_dim_pos',):\n",
    "        output_dim_labels = ('Fixate', 'Cos', '-Cos', 'Sin', '-Sin')\n",
    "    elif task_params['in_out_mode'] in ('low_dim',):\n",
    "        output_dim_labels = ('Fixate', 'Cos', 'Sin')\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def generate_response_stimulus(task_params, test_trials): \n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        labels_resp, labels_stim = [], []\n",
    "        rules_epochs = {} \n",
    "        for rule_idx, rule in enumerate(task_params['rules']):\n",
    "            print(rule)\n",
    "            if rule in accept_rules:\n",
    "                rules_epochs[rule] = test_trials[rule_idx].epochs\n",
    "                if hyp_dict['ruleset'] in ('dmsgo', 'dmcgo'):\n",
    "                    labels.append(test_trials[rule_idx].meta['matches'])\n",
    "                else:\n",
    "                    labels_resp.append(test_trials[rule_idx].meta['resp1'])\n",
    "                    labels_stim.append(test_trials[rule_idx].meta['stim1']) \n",
    "    \n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "        print(rules_epochs)\n",
    "        \n",
    "        labels_resp = np.concatenate(labels_resp, axis=0).reshape(-1,1)\n",
    "        labels_stim = np.concatenate(labels_stim, axis=0).reshape(-1,1)\n",
    "\n",
    "        return labels_resp, labels_stim, rules_epochs\n",
    "\n",
    "    labels_resp, labels_stim, rules_epochs = generate_response_stimulus(task_params, test_trials)\n",
    "\n",
    "\n",
    "labels = labels_stim if color_by == \"stim\" else labels_resp\n",
    "    \n",
    "test_input, test_output, test_mask = test_data\n",
    "\n",
    "permutation = np.random.permutation(test_input.shape[0])\n",
    "test_input = test_input[permutation]\n",
    "test_output = test_output[permutation]\n",
    "test_mask = test_mask[permutation]\n",
    "labels = labels[permutation]\n",
    "\n",
    "test_input_np = test_input.detach().cpu().numpy()\n",
    "test_output_np = test_output.detach().cpu().numpy()\n",
    "\n",
    "# Total number of batches, might be different than test_n_batch\n",
    "# this should be the same regardless of variety of test_input\n",
    "n_batch_all = test_input_np.shape[0] \n",
    "\n",
    "def find_task(task_params, test_input_np, shift_index):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    test_task = [] # which task\n",
    "    for batch_idx in range(test_input_np.shape[0]):\n",
    "        \n",
    "        if task_params[\"randomize_inputs\"]: \n",
    "            test_input_np_ = test_input_np @ np.linalg.pinv(task_params[\"randomize_matrix\"])\n",
    "        else: \n",
    "            test_input_np_ = test_input_np\n",
    "            \n",
    "        task_label = test_input_np_[batch_idx, 0, 6-shift_index:]\n",
    "        \n",
    "        task_label = np.asarray(task_label)       \n",
    "        dist = np.abs(task_label - 1)     \n",
    "        mask = dist == dist.min() \n",
    "        \n",
    "        indices = np.where(mask)[0]\n",
    "        \n",
    "        if indices.size:                \n",
    "            task_label_index = indices[0]   \n",
    "        else:\n",
    "            raise ValueError(\"No entry close enough to 1 found\")\n",
    "            \n",
    "        test_task.append(task_label_index)\n",
    "\n",
    "    return test_task  \n",
    "\n",
    "test_task = find_task(task_params, test_input_np, shift_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b44e9-b6e3-4c1c-a5c7-5a608a6d090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 150, 150, 3]\n",
      "MultiPlastic Net:\n",
      "  output neurons: 3\n",
      "  Act: tanh\n",
      "\n",
      "=== Layer Universal Setup ===\n",
      "150\n",
      "  MP Layer1 parameters:\n",
      "    n_neurons - input: 150, output: 150\n",
      "    M matrix parameters:    update bounds - Max mult: 1.0, Min mult: -1.0\n",
      "      type: mult // Update - type: hebb_assoc // Act fn: linear\n",
      "      Eta: scalar (train) // Lambda: scalar (fixed) // Lambda_max: 0.99 (tau: 4.0e+03)\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "How about Test Data at dataset 0\n",
      "Train parameters:\n",
      "  Loss: MSE // LR: 1.00e-03 // Optim: adam\n",
      "  Grad type: backprop // Gradient clip: 1.0e+01\n",
      "Weight reg: L2, coef: 1.0e-04\n",
      "Activity reg: L2, coef: 1.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gscratch/deepthought/zihan/miniconda3/envs/playground/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, LR: 1.000e-03 - train_loss:5.090e-01, rounded train_acc:0.156, valid_loss:7.843e-01, rounded valid_acc:0.075\n",
      "Iter: 100, LR: 1.000e-03 - train_loss:1.164e-01, rounded train_acc:0.478, valid_loss:5.264e-01, rounded valid_acc:0.173\n",
      "Iter: 200, LR: 1.000e-03 - train_loss:7.148e-02, rounded train_acc:0.758, valid_loss:6.939e-01, rounded valid_acc:0.246\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "How about Test Data at dataset 1\n",
      "Iter: 300, LR: 1.000e-03 - train_loss:1.387e-01, rounded train_acc:0.853, valid_loss:5.981e-01, rounded valid_acc:0.386\n",
      "Iter: 400, LR: 1.000e-03 - train_loss:1.035e-01, rounded train_acc:0.897, valid_loss:6.774e-01, rounded valid_acc:0.360\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 500, LR: 1.000e-03 - train_loss:2.093e-01, rounded train_acc:0.741, valid_loss:5.666e-01, rounded valid_acc:0.237\n",
      "Iter: 600, LR: 1.000e-03 - train_loss:1.478e-01, rounded train_acc:0.827, valid_loss:6.613e-01, rounded valid_acc:0.294\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 700, LR: 1.000e-03 - train_loss:1.824e-01, rounded train_acc:0.782, valid_loss:6.271e-01, rounded valid_acc:0.310\n",
      "Iter: 800, LR: 1.000e-03 - train_loss:1.966e-01, rounded train_acc:0.767, valid_loss:6.115e-01, rounded valid_acc:0.402\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "How about Test Data at dataset 4\n",
      "Iter: 900, LR: 1.000e-03 - train_loss:2.331e-01, rounded train_acc:0.735, valid_loss:4.987e-01, rounded valid_acc:0.393\n",
      "Iter: 1000, LR: 1.000e-03 - train_loss:2.541e-01, rounded train_acc:0.679, valid_loss:5.713e-01, rounded valid_acc:0.315\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 1100, LR: 1.000e-03 - train_loss:1.010e-01, rounded train_acc:0.599, valid_loss:6.790e-01, rounded valid_acc:0.270\n",
      "Iter: 1200, LR: 1.000e-03 - train_loss:6.392e-02, rounded train_acc:0.792, valid_loss:7.594e-01, rounded valid_acc:0.251\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 1300, LR: 1.000e-03 - train_loss:7.144e-02, rounded train_acc:0.755, valid_loss:7.780e-01, rounded valid_acc:0.264\n",
      "Iter: 1400, LR: 1.000e-03 - train_loss:5.230e-02, rounded train_acc:0.844, valid_loss:9.037e-01, rounded valid_acc:0.259\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 1500, LR: 1.000e-03 - train_loss:3.624e-01, rounded train_acc:0.531, valid_loss:4.669e-01, rounded valid_acc:0.306\n",
      "Iter: 1600, LR: 1.000e-03 - train_loss:3.688e-01, rounded train_acc:0.549, valid_loss:5.557e-01, rounded valid_acc:0.236\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 1700, LR: 1.000e-03 - train_loss:7.993e-02, rounded train_acc:0.671, valid_loss:5.541e-01, rounded valid_acc:0.342\n",
      "Iter: 1800, LR: 1.000e-03 - train_loss:5.742e-02, rounded train_acc:0.799, valid_loss:6.293e-01, rounded valid_acc:0.314\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 98, max_seq_len 98\n",
      "inputs_all: torch.Size([256, 98, 11])\n",
      "Iter: 1900, LR: 1.000e-03 - train_loss:6.781e-02, rounded train_acc:0.749, valid_loss:7.355e-01, rounded valid_acc:0.311\n",
      "Iter: 2000, LR: 1.000e-03 - train_loss:5.306e-02, rounded train_acc:0.834, valid_loss:7.789e-01, rounded valid_acc:0.327\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 2100, LR: 1.000e-03 - train_loss:8.098e-02, rounded train_acc:0.673, valid_loss:9.096e-01, rounded valid_acc:0.272\n",
      "Iter: 2200, LR: 1.000e-03 - train_loss:6.148e-02, rounded train_acc:0.773, valid_loss:1.045e+00, rounded valid_acc:0.282\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 2300, LR: 1.000e-03 - train_loss:3.275e-01, rounded train_acc:0.526, valid_loss:6.105e-01, rounded valid_acc:0.246\n",
      "Iter: 2400, LR: 1.000e-03 - train_loss:3.120e-01, rounded train_acc:0.532, valid_loss:5.561e-01, rounded valid_acc:0.190\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 2500, LR: 1.000e-03 - train_loss:7.483e-02, rounded train_acc:0.736, valid_loss:6.420e-01, rounded valid_acc:0.195\n",
      "Iter: 2600, LR: 1.000e-03 - train_loss:5.904e-02, rounded train_acc:0.799, valid_loss:6.525e-01, rounded valid_acc:0.230\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 2700, LR: 1.000e-03 - train_loss:4.659e-01, rounded train_acc:0.363, valid_loss:4.999e-01, rounded valid_acc:0.243\n",
      "Iter: 2800, LR: 1.000e-03 - train_loss:3.911e-01, rounded train_acc:0.474, valid_loss:5.662e-01, rounded valid_acc:0.232\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 2900, LR: 1.000e-03 - train_loss:8.384e-02, rounded train_acc:0.694, valid_loss:6.073e-01, rounded valid_acc:0.242\n",
      "Iter: 3000, LR: 1.000e-03 - train_loss:5.842e-02, rounded train_acc:0.816, valid_loss:6.608e-01, rounded valid_acc:0.233\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 3100, LR: 1.000e-03 - train_loss:6.266e-02, rounded train_acc:0.771, valid_loss:6.842e-01, rounded valid_acc:0.221\n",
      "Iter: 3200, LR: 1.000e-03 - train_loss:4.759e-02, rounded train_acc:0.858, valid_loss:7.881e-01, rounded valid_acc:0.215\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "How about Test Data at dataset 16\n",
      "Iter: 3300, LR: 1.000e-03 - train_loss:4.417e-01, rounded train_acc:0.430, valid_loss:5.023e-01, rounded valid_acc:0.249\n",
      "Iter: 3400, LR: 1.000e-03 - train_loss:4.218e-01, rounded train_acc:0.404, valid_loss:5.484e-01, rounded valid_acc:0.298\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 3500, LR: 1.000e-03 - train_loss:4.681e-01, rounded train_acc:0.441, valid_loss:5.819e-01, rounded valid_acc:0.190\n",
      "Iter: 3600, LR: 1.000e-03 - train_loss:4.225e-01, rounded train_acc:0.433, valid_loss:7.461e-01, rounded valid_acc:0.218\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 3700, LR: 1.000e-03 - train_loss:4.925e-01, rounded train_acc:0.375, valid_loss:5.899e-01, rounded valid_acc:0.197\n",
      "Iter: 3800, LR: 1.000e-03 - train_loss:4.425e-01, rounded train_acc:0.335, valid_loss:6.086e-01, rounded valid_acc:0.198\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 3900, LR: 1.000e-03 - train_loss:1.092e-01, rounded train_acc:0.565, valid_loss:8.497e-01, rounded valid_acc:0.296\n",
      "Iter: 4000, LR: 1.000e-03 - train_loss:8.329e-02, rounded train_acc:0.680, valid_loss:8.951e-01, rounded valid_acc:0.295\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 4100, LR: 1.000e-03 - train_loss:6.827e-02, rounded train_acc:0.738, valid_loss:8.507e-01, rounded valid_acc:0.289\n",
      "Iter: 4200, LR: 1.000e-03 - train_loss:5.509e-02, rounded train_acc:0.833, valid_loss:8.503e-01, rounded valid_acc:0.283\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 4300, LR: 1.000e-03 - train_loss:8.164e-02, rounded train_acc:0.719, valid_loss:6.084e-01, rounded valid_acc:0.354\n",
      "Iter: 4400, LR: 1.000e-03 - train_loss:6.541e-02, rounded train_acc:0.777, valid_loss:6.031e-01, rounded valid_acc:0.329\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 4500, LR: 1.000e-03 - train_loss:5.386e-02, rounded train_acc:0.783, valid_loss:5.885e-01, rounded valid_acc:0.253\n",
      "Iter: 4600, LR: 1.000e-03 - train_loss:4.413e-02, rounded train_acc:0.866, valid_loss:6.143e-01, rounded valid_acc:0.265\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 4700, LR: 1.000e-03 - train_loss:6.319e-02, rounded train_acc:0.785, valid_loss:6.726e-01, rounded valid_acc:0.290\n",
      "Iter: 4800, LR: 1.000e-03 - train_loss:5.951e-02, rounded train_acc:0.808, valid_loss:7.151e-01, rounded valid_acc:0.327\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 4900, LR: 1.000e-03 - train_loss:4.959e-02, rounded train_acc:0.822, valid_loss:6.326e-01, rounded valid_acc:0.218\n",
      "Iter: 5000, LR: 1.000e-03 - train_loss:4.202e-02, rounded train_acc:0.868, valid_loss:5.822e-01, rounded valid_acc:0.203\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 5100, LR: 1.000e-03 - train_loss:6.233e-02, rounded train_acc:0.770, valid_loss:6.418e-01, rounded valid_acc:0.284\n",
      "Iter: 5200, LR: 1.000e-03 - train_loss:4.964e-02, rounded train_acc:0.828, valid_loss:7.341e-01, rounded valid_acc:0.280\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 98, max_seq_len 98\n",
      "inputs_all: torch.Size([256, 98, 11])\n",
      "Iter: 5300, LR: 1.000e-03 - train_loss:4.720e-01, rounded train_acc:0.431, valid_loss:9.367e-01, rounded valid_acc:0.162\n",
      "Iter: 5400, LR: 1.000e-03 - train_loss:3.951e-01, rounded train_acc:0.497, valid_loss:8.392e-01, rounded valid_acc:0.192\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 5500, LR: 1.000e-03 - train_loss:8.198e-02, rounded train_acc:0.678, valid_loss:7.469e-01, rounded valid_acc:0.193\n",
      "Iter: 5600, LR: 1.000e-03 - train_loss:6.670e-02, rounded train_acc:0.741, valid_loss:7.899e-01, rounded valid_acc:0.146\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 5700, LR: 5.000e-04 - train_loss:8.372e-02, rounded train_acc:0.666, valid_loss:6.631e-01, rounded valid_acc:0.155\n",
      "Iter: 5800, LR: 5.000e-04 - train_loss:7.065e-02, rounded train_acc:0.714, valid_loss:6.780e-01, rounded valid_acc:0.147\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 5900, LR: 5.000e-04 - train_loss:4.208e-01, rounded train_acc:0.445, valid_loss:5.510e-01, rounded valid_acc:0.205\n",
      "Iter: 6000, LR: 5.000e-04 - train_loss:3.341e-01, rounded train_acc:0.511, valid_loss:5.959e-01, rounded valid_acc:0.244\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 6100, LR: 5.000e-04 - train_loss:3.871e-01, rounded train_acc:0.469, valid_loss:7.351e-01, rounded valid_acc:0.266\n",
      "Iter: 6200, LR: 5.000e-04 - train_loss:3.232e-01, rounded train_acc:0.553, valid_loss:7.804e-01, rounded valid_acc:0.205\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 6300, LR: 5.000e-04 - train_loss:7.845e-02, rounded train_acc:0.666, valid_loss:6.484e-01, rounded valid_acc:0.233\n",
      "Iter: 6400, LR: 5.000e-04 - train_loss:6.713e-02, rounded train_acc:0.727, valid_loss:6.362e-01, rounded valid_acc:0.236\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 6500, LR: 5.000e-04 - train_loss:2.719e-01, rounded train_acc:0.643, valid_loss:5.106e-01, rounded valid_acc:0.211\n",
      "Iter: 6600, LR: 5.000e-04 - train_loss:2.535e-01, rounded train_acc:0.647, valid_loss:5.581e-01, rounded valid_acc:0.243\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 6700, LR: 5.000e-04 - train_loss:3.386e-01, rounded train_acc:0.567, valid_loss:5.952e-01, rounded valid_acc:0.202\n",
      "Iter: 6800, LR: 5.000e-04 - train_loss:2.580e-01, rounded train_acc:0.702, valid_loss:6.589e-01, rounded valid_acc:0.245\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 6900, LR: 5.000e-04 - train_loss:3.255e-01, rounded train_acc:0.568, valid_loss:6.717e-01, rounded valid_acc:0.255\n",
      "Iter: 7000, LR: 5.000e-04 - train_loss:2.921e-01, rounded train_acc:0.571, valid_loss:6.957e-01, rounded valid_acc:0.272\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 7100, LR: 5.000e-04 - train_loss:2.961e-01, rounded train_acc:0.585, valid_loss:6.583e-01, rounded valid_acc:0.301\n",
      "Iter: 7200, LR: 5.000e-04 - train_loss:2.810e-01, rounded train_acc:0.592, valid_loss:7.602e-01, rounded valid_acc:0.304\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 7300, LR: 5.000e-04 - train_loss:9.088e-02, rounded train_acc:0.623, valid_loss:6.197e-01, rounded valid_acc:0.304\n",
      "Iter: 7400, LR: 5.000e-04 - train_loss:6.894e-02, rounded train_acc:0.730, valid_loss:6.250e-01, rounded valid_acc:0.292\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 7500, LR: 5.000e-04 - train_loss:8.265e-02, rounded train_acc:0.650, valid_loss:5.171e-01, rounded valid_acc:0.349\n",
      "Iter: 7600, LR: 5.000e-04 - train_loss:6.817e-02, rounded train_acc:0.720, valid_loss:5.461e-01, rounded valid_acc:0.285\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 7700, LR: 5.000e-04 - train_loss:3.856e-01, rounded train_acc:0.474, valid_loss:7.737e-01, rounded valid_acc:0.189\n",
      "Iter: 7800, LR: 5.000e-04 - train_loss:3.240e-01, rounded train_acc:0.559, valid_loss:6.734e-01, rounded valid_acc:0.272\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 7900, LR: 5.000e-04 - train_loss:6.542e-02, rounded train_acc:0.716, valid_loss:4.354e-01, rounded valid_acc:0.330\n",
      "Iter: 8000, LR: 5.000e-04 - train_loss:5.511e-02, rounded train_acc:0.803, valid_loss:4.326e-01, rounded valid_acc:0.358\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 8100, LR: 5.000e-04 - train_loss:6.490e-02, rounded train_acc:0.748, valid_loss:6.081e-01, rounded valid_acc:0.278\n",
      "Iter: 8200, LR: 5.000e-04 - train_loss:5.394e-02, rounded train_acc:0.821, valid_loss:6.363e-01, rounded valid_acc:0.290\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 8300, LR: 5.000e-04 - train_loss:5.179e-02, rounded train_acc:0.837, valid_loss:4.896e-01, rounded valid_acc:0.300\n",
      "Iter: 8400, LR: 5.000e-04 - train_loss:4.348e-02, rounded train_acc:0.894, valid_loss:4.838e-01, rounded valid_acc:0.307\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 8500, LR: 5.000e-04 - train_loss:3.830e-01, rounded train_acc:0.502, valid_loss:5.091e-01, rounded valid_acc:0.247\n",
      "Iter: 8600, LR: 5.000e-04 - train_loss:3.038e-01, rounded train_acc:0.575, valid_loss:5.681e-01, rounded valid_acc:0.250\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 8700, LR: 5.000e-04 - train_loss:3.297e-01, rounded train_acc:0.509, valid_loss:5.485e-01, rounded valid_acc:0.286\n",
      "Iter: 8800, LR: 5.000e-04 - train_loss:2.872e-01, rounded train_acc:0.552, valid_loss:6.224e-01, rounded valid_acc:0.267\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 8900, LR: 5.000e-04 - train_loss:5.288e-02, rounded train_acc:0.792, valid_loss:5.181e-01, rounded valid_acc:0.249\n",
      "Iter: 9000, LR: 5.000e-04 - train_loss:4.375e-02, rounded train_acc:0.857, valid_loss:5.057e-01, rounded valid_acc:0.276\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 9100, LR: 5.000e-04 - train_loss:3.489e-01, rounded train_acc:0.550, valid_loss:5.894e-01, rounded valid_acc:0.262\n",
      "Iter: 9200, LR: 5.000e-04 - train_loss:2.731e-01, rounded train_acc:0.620, valid_loss:6.019e-01, rounded valid_acc:0.294\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 9300, LR: 5.000e-04 - train_loss:4.011e-01, rounded train_acc:0.495, valid_loss:4.632e-01, rounded valid_acc:0.335\n",
      "Iter: 9400, LR: 5.000e-04 - train_loss:2.729e-01, rounded train_acc:0.654, valid_loss:4.891e-01, rounded valid_acc:0.347\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 9500, LR: 5.000e-04 - train_loss:3.045e-01, rounded train_acc:0.560, valid_loss:5.913e-01, rounded valid_acc:0.280\n",
      "Iter: 9600, LR: 5.000e-04 - train_loss:2.544e-01, rounded train_acc:0.694, valid_loss:5.602e-01, rounded valid_acc:0.294\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 9700, LR: 5.000e-04 - train_loss:3.247e-01, rounded train_acc:0.566, valid_loss:4.860e-01, rounded valid_acc:0.346\n",
      "Iter: 9800, LR: 5.000e-04 - train_loss:2.595e-01, rounded train_acc:0.591, valid_loss:5.186e-01, rounded valid_acc:0.283\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 9900, LR: 5.000e-04 - train_loss:3.246e-01, rounded train_acc:0.569, valid_loss:4.741e-01, rounded valid_acc:0.291\n",
      "Iter: 10000, LR: 5.000e-04 - train_loss:3.070e-01, rounded train_acc:0.566, valid_loss:4.448e-01, rounded valid_acc:0.325\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 10100, LR: 5.000e-04 - train_loss:6.948e-02, rounded train_acc:0.725, valid_loss:4.225e-01, rounded valid_acc:0.287\n",
      "Iter: 10200, LR: 5.000e-04 - train_loss:5.483e-02, rounded train_acc:0.810, valid_loss:4.459e-01, rounded valid_acc:0.275\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 10300, LR: 2.500e-04 - train_loss:3.109e-01, rounded train_acc:0.574, valid_loss:4.034e-01, rounded valid_acc:0.384\n",
      "Iter: 10400, LR: 2.500e-04 - train_loss:2.348e-01, rounded train_acc:0.708, valid_loss:4.139e-01, rounded valid_acc:0.370\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 10500, LR: 2.500e-04 - train_loss:2.099e-01, rounded train_acc:0.696, valid_loss:4.227e-01, rounded valid_acc:0.345\n",
      "Iter: 10600, LR: 2.500e-04 - train_loss:1.867e-01, rounded train_acc:0.708, valid_loss:4.255e-01, rounded valid_acc:0.323\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 10700, LR: 2.500e-04 - train_loss:8.400e-02, rounded train_acc:0.664, valid_loss:4.075e-01, rounded valid_acc:0.376\n",
      "Iter: 10800, LR: 2.500e-04 - train_loss:6.997e-02, rounded train_acc:0.730, valid_loss:4.203e-01, rounded valid_acc:0.338\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 10900, LR: 2.500e-04 - train_loss:2.898e-01, rounded train_acc:0.606, valid_loss:3.590e-01, rounded valid_acc:0.405\n",
      "Iter: 11000, LR: 2.500e-04 - train_loss:2.175e-01, rounded train_acc:0.706, valid_loss:3.904e-01, rounded valid_acc:0.342\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 11100, LR: 2.500e-04 - train_loss:5.932e-02, rounded train_acc:0.786, valid_loss:3.948e-01, rounded valid_acc:0.335\n",
      "Iter: 11200, LR: 2.500e-04 - train_loss:5.097e-02, rounded train_acc:0.836, valid_loss:4.076e-01, rounded valid_acc:0.291\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 11300, LR: 2.500e-04 - train_loss:2.381e-01, rounded train_acc:0.623, valid_loss:3.799e-01, rounded valid_acc:0.408\n",
      "Iter: 11400, LR: 2.500e-04 - train_loss:1.961e-01, rounded train_acc:0.732, valid_loss:3.887e-01, rounded valid_acc:0.405\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 11500, LR: 2.500e-04 - train_loss:5.386e-02, rounded train_acc:0.802, valid_loss:4.011e-01, rounded valid_acc:0.378\n",
      "Iter: 11600, LR: 2.500e-04 - train_loss:4.742e-02, rounded train_acc:0.849, valid_loss:3.846e-01, rounded valid_acc:0.407\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 98, max_seq_len 98\n",
      "inputs_all: torch.Size([256, 98, 11])\n",
      "Iter: 11700, LR: 2.500e-04 - train_loss:4.710e-02, rounded train_acc:0.852, valid_loss:3.917e-01, rounded valid_acc:0.423\n",
      "Iter: 11800, LR: 2.500e-04 - train_loss:4.056e-02, rounded train_acc:0.885, valid_loss:3.909e-01, rounded valid_acc:0.428\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 11900, LR: 2.500e-04 - train_loss:2.509e-01, rounded train_acc:0.655, valid_loss:3.733e-01, rounded valid_acc:0.384\n",
      "Iter: 12000, LR: 2.500e-04 - train_loss:2.028e-01, rounded train_acc:0.709, valid_loss:3.948e-01, rounded valid_acc:0.377\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 12100, LR: 2.500e-04 - train_loss:1.977e-01, rounded train_acc:0.752, valid_loss:4.062e-01, rounded valid_acc:0.376\n",
      "Iter: 12200, LR: 2.500e-04 - train_loss:1.665e-01, rounded train_acc:0.791, valid_loss:3.819e-01, rounded valid_acc:0.389\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 12300, LR: 2.500e-04 - train_loss:2.779e-01, rounded train_acc:0.629, valid_loss:4.043e-01, rounded valid_acc:0.278\n",
      "Iter: 12400, LR: 2.500e-04 - train_loss:2.286e-01, rounded train_acc:0.681, valid_loss:3.994e-01, rounded valid_acc:0.295\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 12500, LR: 2.500e-04 - train_loss:6.569e-02, rounded train_acc:0.737, valid_loss:4.020e-01, rounded valid_acc:0.289\n",
      "Iter: 12600, LR: 2.500e-04 - train_loss:5.672e-02, rounded train_acc:0.787, valid_loss:4.135e-01, rounded valid_acc:0.283\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 12700, LR: 2.500e-04 - train_loss:5.873e-02, rounded train_acc:0.758, valid_loss:4.612e-01, rounded valid_acc:0.282\n",
      "Iter: 12800, LR: 2.500e-04 - train_loss:4.988e-02, rounded train_acc:0.805, valid_loss:4.664e-01, rounded valid_acc:0.299\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "How about Test Data at dataset 64\n",
      "Iter: 12900, LR: 2.500e-04 - train_loss:5.346e-02, rounded train_acc:0.798, valid_loss:5.039e-01, rounded valid_acc:0.253\n",
      "Iter: 13000, LR: 2.500e-04 - train_loss:4.607e-02, rounded train_acc:0.855, valid_loss:4.973e-01, rounded valid_acc:0.259\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 13100, LR: 2.500e-04 - train_loss:2.538e-01, rounded train_acc:0.629, valid_loss:3.061e-01, rounded valid_acc:0.445\n",
      "Iter: 13200, LR: 2.500e-04 - train_loss:2.393e-01, rounded train_acc:0.619, valid_loss:3.337e-01, rounded valid_acc:0.433\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 13300, LR: 2.500e-04 - train_loss:2.288e-01, rounded train_acc:0.670, valid_loss:3.767e-01, rounded valid_acc:0.377\n",
      "Iter: 13400, LR: 2.500e-04 - train_loss:1.717e-01, rounded train_acc:0.790, valid_loss:3.544e-01, rounded valid_acc:0.452\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 13500, LR: 2.500e-04 - train_loss:5.256e-02, rounded train_acc:0.817, valid_loss:2.995e-01, rounded valid_acc:0.457\n",
      "Iter: 13600, LR: 2.500e-04 - train_loss:4.537e-02, rounded train_acc:0.851, valid_loss:3.069e-01, rounded valid_acc:0.419\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 98, max_seq_len 98\n",
      "inputs_all: torch.Size([256, 98, 11])\n",
      "Iter: 13700, LR: 2.500e-04 - train_loss:2.521e-01, rounded train_acc:0.614, valid_loss:3.510e-01, rounded valid_acc:0.403\n",
      "Iter: 13800, LR: 2.500e-04 - train_loss:1.948e-01, rounded train_acc:0.749, valid_loss:3.634e-01, rounded valid_acc:0.415\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 13900, LR: 2.500e-04 - train_loss:2.271e-01, rounded train_acc:0.677, valid_loss:3.382e-01, rounded valid_acc:0.395\n",
      "Iter: 14000, LR: 2.500e-04 - train_loss:1.951e-01, rounded train_acc:0.735, valid_loss:3.407e-01, rounded valid_acc:0.459\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 14100, LR: 2.500e-04 - train_loss:2.177e-01, rounded train_acc:0.633, valid_loss:3.454e-01, rounded valid_acc:0.391\n",
      "Iter: 14200, LR: 2.500e-04 - train_loss:1.925e-01, rounded train_acc:0.730, valid_loss:3.719e-01, rounded valid_acc:0.357\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 14300, LR: 2.500e-04 - train_loss:5.385e-02, rounded train_acc:0.820, valid_loss:3.175e-01, rounded valid_acc:0.408\n",
      "Iter: 14400, LR: 2.500e-04 - train_loss:4.432e-02, rounded train_acc:0.863, valid_loss:3.194e-01, rounded valid_acc:0.418\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 14500, LR: 2.500e-04 - train_loss:4.944e-02, rounded train_acc:0.838, valid_loss:3.299e-01, rounded valid_acc:0.406\n",
      "Iter: 14600, LR: 2.500e-04 - train_loss:4.249e-02, rounded train_acc:0.878, valid_loss:3.264e-01, rounded valid_acc:0.429\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 14700, LR: 2.500e-04 - train_loss:2.133e-01, rounded train_acc:0.719, valid_loss:2.835e-01, rounded valid_acc:0.451\n",
      "Iter: 14800, LR: 2.500e-04 - train_loss:1.806e-01, rounded train_acc:0.726, valid_loss:2.850e-01, rounded valid_acc:0.418\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 14900, LR: 2.500e-04 - train_loss:5.078e-02, rounded train_acc:0.832, valid_loss:2.859e-01, rounded valid_acc:0.427\n",
      "Iter: 15000, LR: 2.500e-04 - train_loss:4.329e-02, rounded train_acc:0.875, valid_loss:2.856e-01, rounded valid_acc:0.437\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 15100, LR: 2.500e-04 - train_loss:2.304e-01, rounded train_acc:0.681, valid_loss:2.958e-01, rounded valid_acc:0.450\n",
      "Iter: 15200, LR: 2.500e-04 - train_loss:1.676e-01, rounded train_acc:0.774, valid_loss:2.912e-01, rounded valid_acc:0.510\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 98, max_seq_len 98\n",
      "inputs_all: torch.Size([256, 98, 11])\n",
      "Iter: 15300, LR: 2.500e-04 - train_loss:1.919e-01, rounded train_acc:0.723, valid_loss:2.840e-01, rounded valid_acc:0.494\n",
      "Iter: 15400, LR: 2.500e-04 - train_loss:1.747e-01, rounded train_acc:0.721, valid_loss:3.164e-01, rounded valid_acc:0.451\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 15500, LR: 2.500e-04 - train_loss:2.010e-01, rounded train_acc:0.721, valid_loss:3.281e-01, rounded valid_acc:0.441\n",
      "Iter: 15600, LR: 2.500e-04 - train_loss:1.718e-01, rounded train_acc:0.777, valid_loss:3.290e-01, rounded valid_acc:0.437\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 15700, LR: 2.500e-04 - train_loss:2.195e-01, rounded train_acc:0.662, valid_loss:3.841e-01, rounded valid_acc:0.381\n",
      "Iter: 15800, LR: 2.500e-04 - train_loss:1.722e-01, rounded train_acc:0.736, valid_loss:3.850e-01, rounded valid_acc:0.388\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 15900, LR: 2.500e-04 - train_loss:2.044e-01, rounded train_acc:0.669, valid_loss:4.921e-01, rounded valid_acc:0.306\n",
      "Iter: 16000, LR: 2.500e-04 - train_loss:1.754e-01, rounded train_acc:0.743, valid_loss:4.948e-01, rounded valid_acc:0.317\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 16100, LR: 2.500e-04 - train_loss:2.001e-01, rounded train_acc:0.669, valid_loss:3.648e-01, rounded valid_acc:0.422\n",
      "Iter: 16200, LR: 2.500e-04 - train_loss:1.520e-01, rounded train_acc:0.789, valid_loss:3.758e-01, rounded valid_acc:0.430\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 16300, LR: 2.500e-04 - train_loss:5.706e-02, rounded train_acc:0.796, valid_loss:3.315e-01, rounded valid_acc:0.423\n",
      "Iter: 16400, LR: 2.500e-04 - train_loss:4.754e-02, rounded train_acc:0.827, valid_loss:3.407e-01, rounded valid_acc:0.442\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 16500, LR: 2.500e-04 - train_loss:5.465e-02, rounded train_acc:0.801, valid_loss:3.794e-01, rounded valid_acc:0.441\n",
      "Iter: 16600, LR: 2.500e-04 - train_loss:4.610e-02, rounded train_acc:0.852, valid_loss:4.051e-01, rounded valid_acc:0.406\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 16700, LR: 2.500e-04 - train_loss:5.340e-02, rounded train_acc:0.790, valid_loss:3.697e-01, rounded valid_acc:0.450\n",
      "Iter: 16800, LR: 2.500e-04 - train_loss:4.681e-02, rounded train_acc:0.842, valid_loss:3.688e-01, rounded valid_acc:0.449\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 16900, LR: 2.500e-04 - train_loss:4.928e-02, rounded train_acc:0.829, valid_loss:3.927e-01, rounded valid_acc:0.433\n",
      "Iter: 17000, LR: 2.500e-04 - train_loss:4.242e-02, rounded train_acc:0.871, valid_loss:3.862e-01, rounded valid_acc:0.439\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 17100, LR: 1.250e-04 - train_loss:4.736e-02, rounded train_acc:0.839, valid_loss:3.797e-01, rounded valid_acc:0.472\n",
      "Iter: 17200, LR: 1.250e-04 - train_loss:4.117e-02, rounded train_acc:0.869, valid_loss:3.970e-01, rounded valid_acc:0.450\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 98, max_seq_len 98\n",
      "inputs_all: torch.Size([256, 98, 11])\n",
      "Iter: 17300, LR: 1.250e-04 - train_loss:2.272e-01, rounded train_acc:0.682, valid_loss:3.392e-01, rounded valid_acc:0.469\n",
      "Iter: 17400, LR: 1.250e-04 - train_loss:1.983e-01, rounded train_acc:0.705, valid_loss:3.321e-01, rounded valid_acc:0.444\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 17500, LR: 1.250e-04 - train_loss:2.266e-01, rounded train_acc:0.681, valid_loss:3.597e-01, rounded valid_acc:0.362\n",
      "Iter: 17600, LR: 1.250e-04 - train_loss:1.898e-01, rounded train_acc:0.740, valid_loss:3.613e-01, rounded valid_acc:0.426\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 17700, LR: 1.250e-04 - train_loss:5.198e-02, rounded train_acc:0.795, valid_loss:3.608e-01, rounded valid_acc:0.430\n",
      "Iter: 17800, LR: 1.250e-04 - train_loss:4.390e-02, rounded train_acc:0.847, valid_loss:3.724e-01, rounded valid_acc:0.424\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 17900, LR: 1.250e-04 - train_loss:5.457e-02, rounded train_acc:0.802, valid_loss:3.603e-01, rounded valid_acc:0.454\n",
      "Iter: 18000, LR: 1.250e-04 - train_loss:4.816e-02, rounded train_acc:0.844, valid_loss:3.570e-01, rounded valid_acc:0.448\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 18100, LR: 1.250e-04 - train_loss:5.036e-02, rounded train_acc:0.866, valid_loss:3.697e-01, rounded valid_acc:0.446\n",
      "Iter: 18200, LR: 1.250e-04 - train_loss:4.457e-02, rounded train_acc:0.904, valid_loss:3.745e-01, rounded valid_acc:0.447\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 18300, LR: 1.250e-04 - train_loss:4.978e-02, rounded train_acc:0.822, valid_loss:3.555e-01, rounded valid_acc:0.462\n",
      "Iter: 18400, LR: 1.250e-04 - train_loss:4.394e-02, rounded train_acc:0.852, valid_loss:3.624e-01, rounded valid_acc:0.462\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 18500, LR: 1.250e-04 - train_loss:2.330e-01, rounded train_acc:0.705, valid_loss:2.906e-01, rounded valid_acc:0.506\n",
      "Iter: 18600, LR: 1.250e-04 - train_loss:1.783e-01, rounded train_acc:0.780, valid_loss:2.965e-01, rounded valid_acc:0.459\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 18700, LR: 1.250e-04 - train_loss:1.924e-01, rounded train_acc:0.748, valid_loss:2.997e-01, rounded valid_acc:0.458\n",
      "Iter: 18800, LR: 1.250e-04 - train_loss:1.653e-01, rounded train_acc:0.782, valid_loss:3.069e-01, rounded valid_acc:0.436\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 18900, LR: 1.250e-04 - train_loss:5.295e-02, rounded train_acc:0.803, valid_loss:3.191e-01, rounded valid_acc:0.406\n",
      "Iter: 19000, LR: 1.250e-04 - train_loss:4.507e-02, rounded train_acc:0.840, valid_loss:3.230e-01, rounded valid_acc:0.397\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 19100, LR: 1.250e-04 - train_loss:2.500e-01, rounded train_acc:0.625, valid_loss:4.010e-01, rounded valid_acc:0.363\n",
      "Iter: 19200, LR: 1.250e-04 - train_loss:1.983e-01, rounded train_acc:0.737, valid_loss:4.361e-01, rounded valid_acc:0.356\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 19300, LR: 6.250e-05 - train_loss:2.080e-01, rounded train_acc:0.773, valid_loss:2.982e-01, rounded valid_acc:0.494\n",
      "Iter: 19400, LR: 6.250e-05 - train_loss:1.812e-01, rounded train_acc:0.792, valid_loss:3.057e-01, rounded valid_acc:0.479\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 19500, LR: 6.250e-05 - train_loss:2.431e-01, rounded train_acc:0.637, valid_loss:2.917e-01, rounded valid_acc:0.464\n",
      "Iter: 19600, LR: 6.250e-05 - train_loss:2.090e-01, rounded train_acc:0.674, valid_loss:2.853e-01, rounded valid_acc:0.488\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 19700, LR: 6.250e-05 - train_loss:2.677e-01, rounded train_acc:0.598, valid_loss:3.531e-01, rounded valid_acc:0.414\n",
      "Iter: 19800, LR: 6.250e-05 - train_loss:2.376e-01, rounded train_acc:0.685, valid_loss:3.577e-01, rounded valid_acc:0.389\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 19900, LR: 6.250e-05 - train_loss:2.222e-01, rounded train_acc:0.720, valid_loss:2.790e-01, rounded valid_acc:0.561\n",
      "Iter: 20000, LR: 6.250e-05 - train_loss:1.838e-01, rounded train_acc:0.772, valid_loss:2.853e-01, rounded valid_acc:0.542\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 20100, LR: 6.250e-05 - train_loss:2.508e-01, rounded train_acc:0.652, valid_loss:2.985e-01, rounded valid_acc:0.402\n",
      "Iter: 20200, LR: 6.250e-05 - train_loss:2.159e-01, rounded train_acc:0.694, valid_loss:3.067e-01, rounded valid_acc:0.386\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 20300, LR: 6.250e-05 - train_loss:2.339e-01, rounded train_acc:0.682, valid_loss:3.092e-01, rounded valid_acc:0.392\n",
      "Iter: 20400, LR: 6.250e-05 - train_loss:1.961e-01, rounded train_acc:0.756, valid_loss:3.083e-01, rounded valid_acc:0.424\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 20500, LR: 6.250e-05 - train_loss:6.131e-02, rounded train_acc:0.738, valid_loss:2.583e-01, rounded valid_acc:0.543\n",
      "Iter: 20600, LR: 6.250e-05 - train_loss:5.482e-02, rounded train_acc:0.773, valid_loss:2.616e-01, rounded valid_acc:0.536\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 20700, LR: 6.250e-05 - train_loss:4.895e-02, rounded train_acc:0.820, valid_loss:2.443e-01, rounded valid_acc:0.552\n",
      "Iter: 20800, LR: 6.250e-05 - train_loss:4.417e-02, rounded train_acc:0.853, valid_loss:2.416e-01, rounded valid_acc:0.558\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 20900, LR: 6.250e-05 - train_loss:4.988e-02, rounded train_acc:0.817, valid_loss:2.590e-01, rounded valid_acc:0.548\n",
      "Iter: 21000, LR: 6.250e-05 - train_loss:4.477e-02, rounded train_acc:0.852, valid_loss:2.590e-01, rounded valid_acc:0.571\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 21100, LR: 6.250e-05 - train_loss:5.085e-02, rounded train_acc:0.812, valid_loss:2.587e-01, rounded valid_acc:0.546\n",
      "Iter: 21200, LR: 6.250e-05 - train_loss:4.579e-02, rounded train_acc:0.839, valid_loss:2.607e-01, rounded valid_acc:0.521\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 21300, LR: 6.250e-05 - train_loss:1.937e-01, rounded train_acc:0.738, valid_loss:2.536e-01, rounded valid_acc:0.549\n",
      "Iter: 21400, LR: 6.250e-05 - train_loss:1.647e-01, rounded train_acc:0.791, valid_loss:2.476e-01, rounded valid_acc:0.564\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 21500, LR: 6.250e-05 - train_loss:1.843e-01, rounded train_acc:0.752, valid_loss:2.501e-01, rounded valid_acc:0.490\n",
      "Iter: 21600, LR: 6.250e-05 - train_loss:1.619e-01, rounded train_acc:0.814, valid_loss:2.557e-01, rounded valid_acc:0.502\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 21700, LR: 6.250e-05 - train_loss:2.240e-01, rounded train_acc:0.717, valid_loss:2.467e-01, rounded valid_acc:0.486\n",
      "Iter: 21800, LR: 6.250e-05 - train_loss:1.951e-01, rounded train_acc:0.752, valid_loss:2.435e-01, rounded valid_acc:0.463\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 21900, LR: 6.250e-05 - train_loss:5.208e-02, rounded train_acc:0.812, valid_loss:2.488e-01, rounded valid_acc:0.510\n",
      "Iter: 22000, LR: 6.250e-05 - train_loss:4.621e-02, rounded train_acc:0.845, valid_loss:2.537e-01, rounded valid_acc:0.513\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 22100, LR: 6.250e-05 - train_loss:2.154e-01, rounded train_acc:0.730, valid_loss:2.545e-01, rounded valid_acc:0.506\n",
      "Iter: 22200, LR: 6.250e-05 - train_loss:1.953e-01, rounded train_acc:0.763, valid_loss:2.578e-01, rounded valid_acc:0.477\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 22300, LR: 6.250e-05 - train_loss:2.148e-01, rounded train_acc:0.709, valid_loss:2.302e-01, rounded valid_acc:0.492\n",
      "Iter: 22400, LR: 6.250e-05 - train_loss:1.833e-01, rounded train_acc:0.752, valid_loss:2.359e-01, rounded valid_acc:0.476\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 22500, LR: 6.250e-05 - train_loss:5.045e-02, rounded train_acc:0.802, valid_loss:2.421e-01, rounded valid_acc:0.508\n",
      "Iter: 22600, LR: 6.250e-05 - train_loss:4.509e-02, rounded train_acc:0.834, valid_loss:2.394e-01, rounded valid_acc:0.503\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 22700, LR: 6.250e-05 - train_loss:5.253e-02, rounded train_acc:0.806, valid_loss:2.452e-01, rounded valid_acc:0.472\n",
      "Iter: 22800, LR: 6.250e-05 - train_loss:4.761e-02, rounded train_acc:0.836, valid_loss:2.436e-01, rounded valid_acc:0.503\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 22900, LR: 6.250e-05 - train_loss:2.314e-01, rounded train_acc:0.686, valid_loss:2.692e-01, rounded valid_acc:0.436\n",
      "Iter: 23000, LR: 6.250e-05 - train_loss:2.015e-01, rounded train_acc:0.732, valid_loss:2.689e-01, rounded valid_acc:0.489\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 23100, LR: 6.250e-05 - train_loss:2.383e-01, rounded train_acc:0.658, valid_loss:2.859e-01, rounded valid_acc:0.487\n",
      "Iter: 23200, LR: 6.250e-05 - train_loss:2.156e-01, rounded train_acc:0.685, valid_loss:3.012e-01, rounded valid_acc:0.453\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 98, max_seq_len 98\n",
      "inputs_all: torch.Size([256, 98, 11])\n",
      "Iter: 23300, LR: 6.250e-05 - train_loss:4.818e-02, rounded train_acc:0.839, valid_loss:2.754e-01, rounded valid_acc:0.544\n",
      "Iter: 23400, LR: 6.250e-05 - train_loss:4.292e-02, rounded train_acc:0.875, valid_loss:2.678e-01, rounded valid_acc:0.539\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 95, max_seq_len 95\n",
      "inputs_all: torch.Size([256, 95, 11])\n",
      "Iter: 23500, LR: 6.250e-05 - train_loss:1.980e-01, rounded train_acc:0.743, valid_loss:2.447e-01, rounded valid_acc:0.513\n",
      "Iter: 23600, LR: 6.250e-05 - train_loss:1.690e-01, rounded train_acc:0.806, valid_loss:2.437e-01, rounded valid_acc:0.519\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 23700, LR: 6.250e-05 - train_loss:4.562e-02, rounded train_acc:0.837, valid_loss:2.402e-01, rounded valid_acc:0.530\n",
      "Iter: 23800, LR: 6.250e-05 - train_loss:3.983e-02, rounded train_acc:0.874, valid_loss:2.437e-01, rounded valid_acc:0.517\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 23900, LR: 6.250e-05 - train_loss:1.884e-01, rounded train_acc:0.718, valid_loss:2.637e-01, rounded valid_acc:0.456\n",
      "Iter: 24000, LR: 6.250e-05 - train_loss:1.594e-01, rounded train_acc:0.751, valid_loss:2.619e-01, rounded valid_acc:0.505\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 24100, LR: 6.250e-05 - train_loss:1.772e-01, rounded train_acc:0.747, valid_loss:2.365e-01, rounded valid_acc:0.512\n",
      "Iter: 24200, LR: 6.250e-05 - train_loss:1.525e-01, rounded train_acc:0.811, valid_loss:2.369e-01, rounded valid_acc:0.517\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 24300, LR: 6.250e-05 - train_loss:2.082e-01, rounded train_acc:0.718, valid_loss:2.324e-01, rounded valid_acc:0.526\n",
      "Iter: 24400, LR: 6.250e-05 - train_loss:1.768e-01, rounded train_acc:0.793, valid_loss:2.374e-01, rounded valid_acc:0.512\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 98, max_seq_len 98\n",
      "inputs_all: torch.Size([256, 98, 11])\n",
      "Iter: 24500, LR: 6.250e-05 - train_loss:1.970e-01, rounded train_acc:0.735, valid_loss:2.230e-01, rounded valid_acc:0.516\n",
      "Iter: 24600, LR: 6.250e-05 - train_loss:1.677e-01, rounded train_acc:0.788, valid_loss:2.303e-01, rounded valid_acc:0.477\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 24700, LR: 6.250e-05 - train_loss:4.732e-02, rounded train_acc:0.832, valid_loss:2.171e-01, rounded valid_acc:0.503\n",
      "Iter: 24800, LR: 6.250e-05 - train_loss:4.261e-02, rounded train_acc:0.859, valid_loss:2.076e-01, rounded valid_acc:0.506\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 24900, LR: 6.250e-05 - train_loss:1.973e-01, rounded train_acc:0.738, valid_loss:2.233e-01, rounded valid_acc:0.548\n",
      "Iter: 25000, LR: 6.250e-05 - train_loss:1.707e-01, rounded train_acc:0.778, valid_loss:2.165e-01, rounded valid_acc:0.552\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 25100, LR: 6.250e-05 - train_loss:1.998e-01, rounded train_acc:0.747, valid_loss:2.203e-01, rounded valid_acc:0.587\n",
      "Iter: 25200, LR: 6.250e-05 - train_loss:1.609e-01, rounded train_acc:0.806, valid_loss:2.186e-01, rounded valid_acc:0.611\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 25300, LR: 6.250e-05 - train_loss:1.839e-01, rounded train_acc:0.736, valid_loss:2.390e-01, rounded valid_acc:0.524\n",
      "Iter: 25400, LR: 6.250e-05 - train_loss:1.604e-01, rounded train_acc:0.781, valid_loss:2.545e-01, rounded valid_acc:0.496\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 25500, LR: 6.250e-05 - train_loss:2.253e-01, rounded train_acc:0.671, valid_loss:2.533e-01, rounded valid_acc:0.453\n",
      "Iter: 25600, LR: 6.250e-05 - train_loss:1.910e-01, rounded train_acc:0.756, valid_loss:2.650e-01, rounded valid_acc:0.462\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 25700, LR: 6.250e-05 - train_loss:1.831e-01, rounded train_acc:0.718, valid_loss:2.550e-01, rounded valid_acc:0.482\n",
      "Iter: 25800, LR: 6.250e-05 - train_loss:1.641e-01, rounded train_acc:0.744, valid_loss:2.652e-01, rounded valid_acc:0.467\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 25900, LR: 6.250e-05 - train_loss:2.119e-01, rounded train_acc:0.731, valid_loss:2.470e-01, rounded valid_acc:0.483\n",
      "Iter: 26000, LR: 6.250e-05 - train_loss:1.908e-01, rounded train_acc:0.762, valid_loss:2.450e-01, rounded valid_acc:0.532\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 26100, LR: 6.250e-05 - train_loss:5.238e-02, rounded train_acc:0.805, valid_loss:2.346e-01, rounded valid_acc:0.529\n",
      "Iter: 26200, LR: 6.250e-05 - train_loss:4.722e-02, rounded train_acc:0.833, valid_loss:2.367e-01, rounded valid_acc:0.526\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 26300, LR: 6.250e-05 - train_loss:1.896e-01, rounded train_acc:0.713, valid_loss:2.047e-01, rounded valid_acc:0.547\n",
      "Iter: 26400, LR: 6.250e-05 - train_loss:1.612e-01, rounded train_acc:0.762, valid_loss:2.082e-01, rounded valid_acc:0.513\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 26500, LR: 6.250e-05 - train_loss:2.011e-01, rounded train_acc:0.736, valid_loss:2.241e-01, rounded valid_acc:0.547\n",
      "Iter: 26600, LR: 6.250e-05 - train_loss:1.675e-01, rounded train_acc:0.795, valid_loss:2.307e-01, rounded valid_acc:0.516\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 26700, LR: 6.250e-05 - train_loss:1.948e-01, rounded train_acc:0.758, valid_loss:2.471e-01, rounded valid_acc:0.526\n",
      "Iter: 26800, LR: 6.250e-05 - train_loss:1.666e-01, rounded train_acc:0.806, valid_loss:2.596e-01, rounded valid_acc:0.517\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 26900, LR: 6.250e-05 - train_loss:5.409e-02, rounded train_acc:0.778, valid_loss:2.463e-01, rounded valid_acc:0.540\n",
      "Iter: 27000, LR: 6.250e-05 - train_loss:4.803e-02, rounded train_acc:0.832, valid_loss:2.518e-01, rounded valid_acc:0.569\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 27100, LR: 3.125e-05 - train_loss:2.097e-01, rounded train_acc:0.708, valid_loss:2.582e-01, rounded valid_acc:0.517\n",
      "Iter: 27200, LR: 3.125e-05 - train_loss:1.900e-01, rounded train_acc:0.745, valid_loss:2.552e-01, rounded valid_acc:0.503\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 27300, LR: 3.125e-05 - train_loss:2.215e-01, rounded train_acc:0.683, valid_loss:2.103e-01, rounded valid_acc:0.498\n",
      "Iter: 27400, LR: 3.125e-05 - train_loss:1.909e-01, rounded train_acc:0.742, valid_loss:1.989e-01, rounded valid_acc:0.547\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 27500, LR: 3.125e-05 - train_loss:5.444e-02, rounded train_acc:0.795, valid_loss:1.944e-01, rounded valid_acc:0.561\n",
      "Iter: 27600, LR: 3.125e-05 - train_loss:4.983e-02, rounded train_acc:0.821, valid_loss:1.946e-01, rounded valid_acc:0.566\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 27700, LR: 3.125e-05 - train_loss:2.092e-01, rounded train_acc:0.693, valid_loss:2.242e-01, rounded valid_acc:0.589\n",
      "Iter: 27800, LR: 3.125e-05 - train_loss:1.842e-01, rounded train_acc:0.754, valid_loss:2.267e-01, rounded valid_acc:0.597\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 27900, LR: 3.125e-05 - train_loss:2.308e-01, rounded train_acc:0.682, valid_loss:1.915e-01, rounded valid_acc:0.620\n",
      "Iter: 28000, LR: 3.125e-05 - train_loss:2.011e-01, rounded train_acc:0.731, valid_loss:1.986e-01, rounded valid_acc:0.600\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 28100, LR: 3.125e-05 - train_loss:2.162e-01, rounded train_acc:0.680, valid_loss:2.060e-01, rounded valid_acc:0.581\n",
      "Iter: 28200, LR: 3.125e-05 - train_loss:1.954e-01, rounded train_acc:0.712, valid_loss:1.994e-01, rounded valid_acc:0.585\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 28300, LR: 3.125e-05 - train_loss:5.820e-02, rounded train_acc:0.768, valid_loss:1.946e-01, rounded valid_acc:0.571\n",
      "Iter: 28400, LR: 3.125e-05 - train_loss:5.191e-02, rounded train_acc:0.804, valid_loss:1.964e-01, rounded valid_acc:0.571\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 28500, LR: 3.125e-05 - train_loss:2.388e-01, rounded train_acc:0.687, valid_loss:1.882e-01, rounded valid_acc:0.607\n",
      "Iter: 28600, LR: 3.125e-05 - train_loss:2.130e-01, rounded train_acc:0.722, valid_loss:1.843e-01, rounded valid_acc:0.623\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 28700, LR: 3.125e-05 - train_loss:2.187e-01, rounded train_acc:0.660, valid_loss:1.970e-01, rounded valid_acc:0.642\n",
      "Iter: 28800, LR: 3.125e-05 - train_loss:1.970e-01, rounded train_acc:0.673, valid_loss:2.053e-01, rounded valid_acc:0.621\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 28900, LR: 3.125e-05 - train_loss:5.600e-02, rounded train_acc:0.775, valid_loss:1.992e-01, rounded valid_acc:0.629\n",
      "Iter: 29000, LR: 3.125e-05 - train_loss:5.025e-02, rounded train_acc:0.806, valid_loss:1.993e-01, rounded valid_acc:0.634\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 29100, LR: 3.125e-05 - train_loss:5.470e-02, rounded train_acc:0.804, valid_loss:1.959e-01, rounded valid_acc:0.634\n",
      "Iter: 29200, LR: 3.125e-05 - train_loss:4.933e-02, rounded train_acc:0.831, valid_loss:1.947e-01, rounded valid_acc:0.646\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 29300, LR: 3.125e-05 - train_loss:5.403e-02, rounded train_acc:0.776, valid_loss:1.980e-01, rounded valid_acc:0.585\n",
      "Iter: 29400, LR: 3.125e-05 - train_loss:4.933e-02, rounded train_acc:0.799, valid_loss:1.994e-01, rounded valid_acc:0.572\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 29500, LR: 3.125e-05 - train_loss:2.104e-01, rounded train_acc:0.718, valid_loss:1.975e-01, rounded valid_acc:0.604\n",
      "Iter: 29600, LR: 3.125e-05 - train_loss:1.842e-01, rounded train_acc:0.752, valid_loss:1.935e-01, rounded valid_acc:0.601\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 29700, LR: 3.125e-05 - train_loss:4.478e-02, rounded train_acc:0.807, valid_loss:1.938e-01, rounded valid_acc:0.625\n",
      "Iter: 29800, LR: 3.125e-05 - train_loss:4.138e-02, rounded train_acc:0.834, valid_loss:1.959e-01, rounded valid_acc:0.618\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 29900, LR: 3.125e-05 - train_loss:4.815e-02, rounded train_acc:0.821, valid_loss:1.953e-01, rounded valid_acc:0.591\n",
      "Iter: 30000, LR: 3.125e-05 - train_loss:4.444e-02, rounded train_acc:0.847, valid_loss:1.952e-01, rounded valid_acc:0.605\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 30100, LR: 3.125e-05 - train_loss:5.324e-02, rounded train_acc:0.789, valid_loss:1.968e-01, rounded valid_acc:0.578\n",
      "Iter: 30200, LR: 3.125e-05 - train_loss:4.871e-02, rounded train_acc:0.817, valid_loss:1.965e-01, rounded valid_acc:0.588\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 30300, LR: 3.125e-05 - train_loss:1.799e-01, rounded train_acc:0.689, valid_loss:2.125e-01, rounded valid_acc:0.518\n",
      "Iter: 30400, LR: 3.125e-05 - train_loss:1.574e-01, rounded train_acc:0.726, valid_loss:2.199e-01, rounded valid_acc:0.512\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 30500, LR: 3.125e-05 - train_loss:5.294e-02, rounded train_acc:0.818, valid_loss:1.901e-01, rounded valid_acc:0.582\n",
      "Iter: 30600, LR: 3.125e-05 - train_loss:4.868e-02, rounded train_acc:0.843, valid_loss:1.928e-01, rounded valid_acc:0.567\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 30700, LR: 3.125e-05 - train_loss:2.253e-01, rounded train_acc:0.685, valid_loss:2.028e-01, rounded valid_acc:0.539\n",
      "Iter: 30800, LR: 3.125e-05 - train_loss:1.987e-01, rounded train_acc:0.758, valid_loss:1.978e-01, rounded valid_acc:0.533\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 30900, LR: 1.563e-05 - train_loss:2.177e-01, rounded train_acc:0.644, valid_loss:1.884e-01, rounded valid_acc:0.598\n",
      "Iter: 31000, LR: 1.563e-05 - train_loss:1.920e-01, rounded train_acc:0.697, valid_loss:1.913e-01, rounded valid_acc:0.600\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 31100, LR: 1.563e-05 - train_loss:2.673e-01, rounded train_acc:0.609, valid_loss:2.041e-01, rounded valid_acc:0.536\n",
      "Iter: 31200, LR: 1.563e-05 - train_loss:2.361e-01, rounded train_acc:0.664, valid_loss:2.077e-01, rounded valid_acc:0.529\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 31300, LR: 1.563e-05 - train_loss:2.370e-01, rounded train_acc:0.650, valid_loss:1.984e-01, rounded valid_acc:0.609\n",
      "Iter: 31400, LR: 1.563e-05 - train_loss:2.101e-01, rounded train_acc:0.689, valid_loss:1.960e-01, rounded valid_acc:0.621\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 31500, LR: 1.563e-05 - train_loss:5.611e-02, rounded train_acc:0.772, valid_loss:1.932e-01, rounded valid_acc:0.624\n",
      "Iter: 31600, LR: 1.563e-05 - train_loss:5.235e-02, rounded train_acc:0.790, valid_loss:1.929e-01, rounded valid_acc:0.612\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 31700, LR: 1.563e-05 - train_loss:4.967e-02, rounded train_acc:0.805, valid_loss:1.973e-01, rounded valid_acc:0.573\n",
      "Iter: 31800, LR: 1.563e-05 - train_loss:4.596e-02, rounded train_acc:0.830, valid_loss:1.976e-01, rounded valid_acc:0.569\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 31900, LR: 1.563e-05 - train_loss:2.214e-01, rounded train_acc:0.644, valid_loss:1.960e-01, rounded valid_acc:0.617\n",
      "Iter: 32000, LR: 1.563e-05 - train_loss:1.964e-01, rounded train_acc:0.702, valid_loss:1.925e-01, rounded valid_acc:0.614\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 32100, LR: 1.563e-05 - train_loss:2.442e-01, rounded train_acc:0.640, valid_loss:1.979e-01, rounded valid_acc:0.551\n",
      "Iter: 32200, LR: 1.563e-05 - train_loss:2.168e-01, rounded train_acc:0.688, valid_loss:1.986e-01, rounded valid_acc:0.555\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 32300, LR: 1.563e-05 - train_loss:2.433e-01, rounded train_acc:0.669, valid_loss:1.851e-01, rounded valid_acc:0.607\n",
      "Iter: 32400, LR: 1.563e-05 - train_loss:2.238e-01, rounded train_acc:0.699, valid_loss:1.857e-01, rounded valid_acc:0.586\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 32500, LR: 1.563e-05 - train_loss:2.034e-01, rounded train_acc:0.712, valid_loss:1.901e-01, rounded valid_acc:0.619\n",
      "Iter: 32600, LR: 1.563e-05 - train_loss:1.805e-01, rounded train_acc:0.753, valid_loss:1.895e-01, rounded valid_acc:0.614\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 32700, LR: 1.563e-05 - train_loss:4.902e-02, rounded train_acc:0.823, valid_loss:1.848e-01, rounded valid_acc:0.618\n",
      "Iter: 32800, LR: 1.563e-05 - train_loss:4.596e-02, rounded train_acc:0.840, valid_loss:1.863e-01, rounded valid_acc:0.629\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 32900, LR: 1.563e-05 - train_loss:5.433e-02, rounded train_acc:0.786, valid_loss:1.807e-01, rounded valid_acc:0.628\n",
      "Iter: 33000, LR: 1.563e-05 - train_loss:5.067e-02, rounded train_acc:0.812, valid_loss:1.817e-01, rounded valid_acc:0.613\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 33100, LR: 1.563e-05 - train_loss:2.348e-01, rounded train_acc:0.666, valid_loss:1.927e-01, rounded valid_acc:0.572\n",
      "Iter: 33200, LR: 1.563e-05 - train_loss:2.150e-01, rounded train_acc:0.690, valid_loss:1.938e-01, rounded valid_acc:0.573\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 33300, LR: 1.563e-05 - train_loss:4.855e-02, rounded train_acc:0.826, valid_loss:1.875e-01, rounded valid_acc:0.607\n",
      "Iter: 33400, LR: 1.563e-05 - train_loss:4.582e-02, rounded train_acc:0.844, valid_loss:1.862e-01, rounded valid_acc:0.630\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 33500, LR: 1.563e-05 - train_loss:2.061e-01, rounded train_acc:0.725, valid_loss:1.816e-01, rounded valid_acc:0.631\n",
      "Iter: 33600, LR: 1.563e-05 - train_loss:1.839e-01, rounded train_acc:0.747, valid_loss:1.819e-01, rounded valid_acc:0.617\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 33700, LR: 1.563e-05 - train_loss:2.254e-01, rounded train_acc:0.690, valid_loss:1.813e-01, rounded valid_acc:0.629\n",
      "Iter: 33800, LR: 1.563e-05 - train_loss:2.021e-01, rounded train_acc:0.724, valid_loss:1.784e-01, rounded valid_acc:0.610\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 33900, LR: 1.563e-05 - train_loss:2.045e-01, rounded train_acc:0.691, valid_loss:1.855e-01, rounded valid_acc:0.646\n",
      "Iter: 34000, LR: 1.563e-05 - train_loss:1.836e-01, rounded train_acc:0.736, valid_loss:1.849e-01, rounded valid_acc:0.638\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 34100, LR: 1.563e-05 - train_loss:5.224e-02, rounded train_acc:0.791, valid_loss:1.808e-01, rounded valid_acc:0.612\n",
      "Iter: 34200, LR: 1.563e-05 - train_loss:4.931e-02, rounded train_acc:0.809, valid_loss:1.818e-01, rounded valid_acc:0.607\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 34300, LR: 1.563e-05 - train_loss:2.021e-01, rounded train_acc:0.703, valid_loss:1.865e-01, rounded valid_acc:0.636\n",
      "Iter: 34400, LR: 1.563e-05 - train_loss:1.783e-01, rounded train_acc:0.745, valid_loss:1.852e-01, rounded valid_acc:0.635\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 34500, LR: 1.563e-05 - train_loss:1.904e-01, rounded train_acc:0.711, valid_loss:1.930e-01, rounded valid_acc:0.644\n",
      "Iter: 34600, LR: 1.563e-05 - train_loss:1.742e-01, rounded train_acc:0.722, valid_loss:1.949e-01, rounded valid_acc:0.641\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 34700, LR: 1.563e-05 - train_loss:2.426e-01, rounded train_acc:0.690, valid_loss:1.861e-01, rounded valid_acc:0.660\n",
      "Iter: 34800, LR: 1.563e-05 - train_loss:2.176e-01, rounded train_acc:0.708, valid_loss:1.841e-01, rounded valid_acc:0.656\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 34900, LR: 1.563e-05 - train_loss:5.479e-02, rounded train_acc:0.805, valid_loss:1.800e-01, rounded valid_acc:0.624\n",
      "Iter: 35000, LR: 1.563e-05 - train_loss:5.040e-02, rounded train_acc:0.829, valid_loss:1.798e-01, rounded valid_acc:0.626\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 97, max_seq_len 97\n",
      "inputs_all: torch.Size([256, 97, 11])\n",
      "Iter: 35100, LR: 1.563e-05 - train_loss:5.243e-02, rounded train_acc:0.805, valid_loss:1.821e-01, rounded valid_acc:0.620\n",
      "Iter: 35200, LR: 1.563e-05 - train_loss:4.928e-02, rounded train_acc:0.817, valid_loss:1.820e-01, rounded valid_acc:0.630\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 35300, LR: 1.563e-05 - train_loss:5.305e-02, rounded train_acc:0.799, valid_loss:1.819e-01, rounded valid_acc:0.629\n",
      "Iter: 35400, LR: 1.563e-05 - train_loss:5.027e-02, rounded train_acc:0.819, valid_loss:1.829e-01, rounded valid_acc:0.617\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 35500, LR: 1.563e-05 - train_loss:5.406e-02, rounded train_acc:0.806, valid_loss:1.853e-01, rounded valid_acc:0.600\n",
      "Iter: 35600, LR: 1.563e-05 - train_loss:5.062e-02, rounded train_acc:0.818, valid_loss:1.872e-01, rounded valid_acc:0.602\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 35700, LR: 1.563e-05 - train_loss:2.088e-01, rounded train_acc:0.690, valid_loss:1.903e-01, rounded valid_acc:0.623\n",
      "Iter: 35800, LR: 1.563e-05 - train_loss:1.830e-01, rounded train_acc:0.714, valid_loss:1.830e-01, rounded valid_acc:0.634\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 35900, LR: 1.563e-05 - train_loss:2.058e-01, rounded train_acc:0.692, valid_loss:1.862e-01, rounded valid_acc:0.643\n",
      "Iter: 36000, LR: 1.563e-05 - train_loss:1.867e-01, rounded train_acc:0.706, valid_loss:1.885e-01, rounded valid_acc:0.657\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 36100, LR: 7.813e-06 - train_loss:2.211e-01, rounded train_acc:0.713, valid_loss:1.952e-01, rounded valid_acc:0.613\n",
      "Iter: 36200, LR: 7.813e-06 - train_loss:2.033e-01, rounded train_acc:0.730, valid_loss:1.920e-01, rounded valid_acc:0.618\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 36300, LR: 7.813e-06 - train_loss:5.188e-02, rounded train_acc:0.789, valid_loss:1.939e-01, rounded valid_acc:0.629\n",
      "Iter: 36400, LR: 7.813e-06 - train_loss:4.913e-02, rounded train_acc:0.804, valid_loss:1.935e-01, rounded valid_acc:0.628\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 36500, LR: 7.813e-06 - train_loss:2.128e-01, rounded train_acc:0.712, valid_loss:1.871e-01, rounded valid_acc:0.609\n",
      "Iter: 36600, LR: 7.813e-06 - train_loss:1.991e-01, rounded train_acc:0.735, valid_loss:1.851e-01, rounded valid_acc:0.617\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 98, max_seq_len 98\n",
      "inputs_all: torch.Size([256, 98, 11])\n",
      "Iter: 36700, LR: 7.813e-06 - train_loss:2.428e-01, rounded train_acc:0.669, valid_loss:1.778e-01, rounded valid_acc:0.644\n",
      "Iter: 36800, LR: 7.813e-06 - train_loss:2.250e-01, rounded train_acc:0.706, valid_loss:1.818e-01, rounded valid_acc:0.633\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 36900, LR: 7.813e-06 - train_loss:2.144e-01, rounded train_acc:0.699, valid_loss:1.810e-01, rounded valid_acc:0.637\n",
      "Iter: 37000, LR: 7.813e-06 - train_loss:1.992e-01, rounded train_acc:0.706, valid_loss:1.808e-01, rounded valid_acc:0.652\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 37100, LR: 7.813e-06 - train_loss:5.198e-02, rounded train_acc:0.810, valid_loss:1.783e-01, rounded valid_acc:0.651\n",
      "Iter: 37200, LR: 7.813e-06 - train_loss:4.904e-02, rounded train_acc:0.831, valid_loss:1.780e-01, rounded valid_acc:0.645\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 37300, LR: 7.813e-06 - train_loss:2.358e-01, rounded train_acc:0.648, valid_loss:1.769e-01, rounded valid_acc:0.627\n",
      "Iter: 37400, LR: 7.813e-06 - train_loss:2.227e-01, rounded train_acc:0.669, valid_loss:1.751e-01, rounded valid_acc:0.644\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 37500, LR: 7.813e-06 - train_loss:5.264e-02, rounded train_acc:0.794, valid_loss:1.719e-01, rounded valid_acc:0.665\n",
      "Iter: 37600, LR: 7.813e-06 - train_loss:5.005e-02, rounded train_acc:0.813, valid_loss:1.697e-01, rounded valid_acc:0.669\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 37700, LR: 7.813e-06 - train_loss:5.770e-02, rounded train_acc:0.765, valid_loss:1.767e-01, rounded valid_acc:0.633\n",
      "Iter: 37800, LR: 7.813e-06 - train_loss:5.399e-02, rounded train_acc:0.787, valid_loss:1.756e-01, rounded valid_acc:0.643\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 37900, LR: 7.813e-06 - train_loss:2.236e-01, rounded train_acc:0.703, valid_loss:1.713e-01, rounded valid_acc:0.686\n",
      "Iter: 38000, LR: 7.813e-06 - train_loss:2.097e-01, rounded train_acc:0.732, valid_loss:1.705e-01, rounded valid_acc:0.664\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 38100, LR: 7.813e-06 - train_loss:2.422e-01, rounded train_acc:0.658, valid_loss:1.725e-01, rounded valid_acc:0.663\n",
      "Iter: 38200, LR: 7.813e-06 - train_loss:2.281e-01, rounded train_acc:0.686, valid_loss:1.716e-01, rounded valid_acc:0.658\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 38300, LR: 7.813e-06 - train_loss:2.280e-01, rounded train_acc:0.658, valid_loss:1.767e-01, rounded valid_acc:0.598\n",
      "Iter: 38400, LR: 7.813e-06 - train_loss:2.133e-01, rounded train_acc:0.681, valid_loss:1.812e-01, rounded valid_acc:0.578\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 38500, LR: 7.813e-06 - train_loss:2.407e-01, rounded train_acc:0.622, valid_loss:1.776e-01, rounded valid_acc:0.618\n",
      "Iter: 38600, LR: 7.813e-06 - train_loss:2.282e-01, rounded train_acc:0.658, valid_loss:1.765e-01, rounded valid_acc:0.640\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 38700, LR: 7.813e-06 - train_loss:5.394e-02, rounded train_acc:0.782, valid_loss:1.743e-01, rounded valid_acc:0.640\n",
      "Iter: 38800, LR: 7.813e-06 - train_loss:5.124e-02, rounded train_acc:0.791, valid_loss:1.732e-01, rounded valid_acc:0.634\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 38900, LR: 7.813e-06 - train_loss:5.957e-02, rounded train_acc:0.757, valid_loss:1.712e-01, rounded valid_acc:0.653\n",
      "Iter: 39000, LR: 7.813e-06 - train_loss:5.719e-02, rounded train_acc:0.773, valid_loss:1.709e-01, rounded valid_acc:0.660\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 39100, LR: 7.813e-06 - train_loss:2.284e-01, rounded train_acc:0.677, valid_loss:1.767e-01, rounded valid_acc:0.592\n",
      "Iter: 39200, LR: 7.813e-06 - train_loss:2.118e-01, rounded train_acc:0.707, valid_loss:1.775e-01, rounded valid_acc:0.594\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 39300, LR: 7.813e-06 - train_loss:2.308e-01, rounded train_acc:0.649, valid_loss:1.748e-01, rounded valid_acc:0.585\n",
      "Iter: 39400, LR: 7.813e-06 - train_loss:2.119e-01, rounded train_acc:0.684, valid_loss:1.758e-01, rounded valid_acc:0.588\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 39500, LR: 7.813e-06 - train_loss:5.633e-02, rounded train_acc:0.786, valid_loss:1.737e-01, rounded valid_acc:0.607\n",
      "Iter: 39600, LR: 7.813e-06 - train_loss:5.311e-02, rounded train_acc:0.807, valid_loss:1.740e-01, rounded valid_acc:0.610\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 39700, LR: 7.813e-06 - train_loss:5.749e-02, rounded train_acc:0.750, valid_loss:1.757e-01, rounded valid_acc:0.593\n",
      "Iter: 39800, LR: 7.813e-06 - train_loss:5.466e-02, rounded train_acc:0.772, valid_loss:1.759e-01, rounded valid_acc:0.590\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 39900, LR: 3.906e-06 - train_loss:2.656e-01, rounded train_acc:0.598, valid_loss:1.884e-01, rounded valid_acc:0.565\n",
      "Iter: 40000, LR: 3.906e-06 - train_loss:2.512e-01, rounded train_acc:0.626, valid_loss:1.852e-01, rounded valid_acc:0.585\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 40100, LR: 3.906e-06 - train_loss:5.671e-02, rounded train_acc:0.803, valid_loss:1.798e-01, rounded valid_acc:0.606\n",
      "Iter: 40200, LR: 3.906e-06 - train_loss:5.440e-02, rounded train_acc:0.817, valid_loss:1.776e-01, rounded valid_acc:0.612\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 40300, LR: 3.906e-06 - train_loss:1.985e-01, rounded train_acc:0.722, valid_loss:1.738e-01, rounded valid_acc:0.621\n",
      "Iter: 40400, LR: 3.906e-06 - train_loss:1.881e-01, rounded train_acc:0.739, valid_loss:1.730e-01, rounded valid_acc:0.631\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 40500, LR: 3.906e-06 - train_loss:5.766e-02, rounded train_acc:0.770, valid_loss:1.716e-01, rounded valid_acc:0.643\n",
      "Iter: 40600, LR: 3.906e-06 - train_loss:5.565e-02, rounded train_acc:0.785, valid_loss:1.703e-01, rounded valid_acc:0.644\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 40700, LR: 3.906e-06 - train_loss:2.263e-01, rounded train_acc:0.649, valid_loss:1.722e-01, rounded valid_acc:0.679\n",
      "Iter: 40800, LR: 3.906e-06 - train_loss:2.112e-01, rounded train_acc:0.681, valid_loss:1.736e-01, rounded valid_acc:0.674\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 40900, LR: 3.906e-06 - train_loss:2.255e-01, rounded train_acc:0.682, valid_loss:1.732e-01, rounded valid_acc:0.677\n",
      "Iter: 41000, LR: 3.906e-06 - train_loss:2.141e-01, rounded train_acc:0.704, valid_loss:1.711e-01, rounded valid_acc:0.685\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 41100, LR: 3.906e-06 - train_loss:2.553e-01, rounded train_acc:0.646, valid_loss:1.716e-01, rounded valid_acc:0.680\n",
      "Iter: 41200, LR: 3.906e-06 - train_loss:2.416e-01, rounded train_acc:0.658, valid_loss:1.723e-01, rounded valid_acc:0.668\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 103, max_seq_len 103\n",
      "inputs_all: torch.Size([256, 103, 11])\n",
      "Iter: 41300, LR: 3.906e-06 - train_loss:2.331e-01, rounded train_acc:0.712, valid_loss:1.737e-01, rounded valid_acc:0.677\n",
      "Iter: 41400, LR: 3.906e-06 - train_loss:2.191e-01, rounded train_acc:0.735, valid_loss:1.723e-01, rounded valid_acc:0.685\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 41500, LR: 3.906e-06 - train_loss:5.955e-02, rounded train_acc:0.783, valid_loss:1.702e-01, rounded valid_acc:0.708\n",
      "Iter: 41600, LR: 3.906e-06 - train_loss:5.708e-02, rounded train_acc:0.796, valid_loss:1.707e-01, rounded valid_acc:0.706\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n",
      "Iter: 41700, LR: 3.906e-06 - train_loss:5.659e-02, rounded train_acc:0.757, valid_loss:1.727e-01, rounded valid_acc:0.699\n",
      "Iter: 41800, LR: 3.906e-06 - train_loss:5.490e-02, rounded train_acc:0.763, valid_loss:1.722e-01, rounded valid_acc:0.699\n",
      "Rule: contextdelaydm2\n",
      "Rule contextdelaydm2 seq_len 100, max_seq_len 100\n",
      "inputs_all: torch.Size([256, 100, 11])\n",
      "Iter: 41900, LR: 3.906e-06 - train_loss:2.482e-01, rounded train_acc:0.662, valid_loss:1.784e-01, rounded valid_acc:0.636\n",
      "Iter: 42000, LR: 3.906e-06 - train_loss:2.318e-01, rounded train_acc:0.681, valid_loss:1.793e-01, rounded valid_acc:0.628\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 42100, LR: 1.953e-06 - train_loss:5.520e-02, rounded train_acc:0.789, valid_loss:1.772e-01, rounded valid_acc:0.638\n",
      "Iter: 42200, LR: 1.953e-06 - train_loss:5.305e-02, rounded train_acc:0.804, valid_loss:1.770e-01, rounded valid_acc:0.639\n",
      "Rule: multidelaydm\n",
      "Rule multidelaydm seq_len 102, max_seq_len 102\n",
      "inputs_all: torch.Size([256, 102, 11])\n",
      "Iter: 42300, LR: 1.953e-06 - train_loss:2.412e-01, rounded train_acc:0.655, valid_loss:1.701e-01, rounded valid_acc:0.644\n",
      "Iter: 42400, LR: 1.953e-06 - train_loss:2.339e-01, rounded train_acc:0.667, valid_loss:1.695e-01, rounded valid_acc:0.651\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 101, max_seq_len 101\n",
      "inputs_all: torch.Size([256, 101, 11])\n",
      "Iter: 42500, LR: 1.953e-06 - train_loss:6.074e-02, rounded train_acc:0.753, valid_loss:1.713e-01, rounded valid_acc:0.647\n",
      "Iter: 42600, LR: 1.953e-06 - train_loss:5.844e-02, rounded train_acc:0.766, valid_loss:1.711e-01, rounded valid_acc:0.651\n",
      "Rule: contextdelaydm1\n",
      "Rule contextdelaydm1 seq_len 99, max_seq_len 99\n",
      "inputs_all: torch.Size([256, 99, 11])\n",
      "Iter: 42700, LR: 1.953e-06 - train_loss:2.131e-01, rounded train_acc:0.708, valid_loss:1.707e-01, rounded valid_acc:0.640\n",
      "Iter: 42800, LR: 1.953e-06 - train_loss:2.035e-01, rounded train_acc:0.716, valid_loss:1.705e-01, rounded valid_acc:0.639\n",
      "Rule: delaydm2\n",
      "Rule delaydm2 seq_len 104, max_seq_len 104\n",
      "inputs_all: torch.Size([256, 104, 11])\n"
     ]
    }
   ],
   "source": [
    "# we use net at different training stage on the same test_input\n",
    "net, _, (counter_lst, netout_lst, db_lst, Winput_lst, Winputbias_lst,\\\n",
    "         Woutput_lst, Wall_lst, marker_lst, loss_lst, acc_lst) = net_helpers.train_network(params, device=device, verbose=verbose,\\\n",
    "                                                                                           train=train, hyp_dict=hyp_dict,\\\n",
    "                                                                                           netFunction=netFunction,\\\n",
    "                                                                                           test_input=[test_input])\n",
    "counter_lst = [x * epoch_multiply + 1 for x in counter_lst] # avoid log plot issue    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07eee03-d879-44bc-89ef-60f11bdf721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyp_dict['chosen_network'] == \"dmpn\":\n",
    "    if net_params[\"input_layer_add\"]:\n",
    "        fignorm, axsnorm = plt.subplots(1,1,figsize=(4,4))\n",
    "        axsnorm.plot(counter_lst, [np.linalg.norm(Winput_matrix) for Winput_matrix in Winput_lst], \"-o\")\n",
    "        axsnorm.set_xscale(\"log\")\n",
    "        axsnorm.set_ylabel(\"Frobenius Norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0805a-0938-48e5-976d-3682d45b4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check, if W_freeze, then the recorded W matrix for the modulation layer should not be changed\n",
    "if net_params[\"ml_params\"][\"W_freeze\"]: \n",
    "    assert np.allclose(Wall_lst[-1][0], Wall_lst[0][0])\n",
    "\n",
    "if net_params[\"input_layer_bias\"]: \n",
    "    assert net_params[\"input_layer_add\"] is True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47256480-5b47-496e-887e-b8de35dcc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    fig, ax = plt.subplots(1,1,figsize=(3,3))\n",
    "    ax.plot(net.hist['iters_monitor'][1:], net.hist['train_acc'][1:], color=c_vals[0], label='Full train accuracy')\n",
    "    ax.plot(net.hist['iters_monitor'][1:], net.hist['valid_acc'][1:], color=c_vals[1], label='Full valid accuracy')\n",
    "    if net.weight_reg is not None:\n",
    "        ax.plot(net.hist['iters_monitor'], net.hist['train_loss_output_label'], color=c_vals_l[0], zorder=-1, label='Output label')\n",
    "        ax.plot(net.hist['iters_monitor'], net.hist['train_loss_reg_term'], color=c_vals_l[0], zorder=-1, label='Reg term', linestyle='dashed')\n",
    "        ax.plot(net.hist['iters_monitor'], net.hist['valid_loss_output_label'], color=c_vals_l[1], zorder=-1, label='Output valid label')\n",
    "        ax.plot(net.hist['iters_monitor'], net.hist['valid_loss_reg_term'], color=c_vals_l[1], zorder=-1, label='Reg valid term', linestyle='dashed')\n",
    "    \n",
    "    # ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_ylim([0.5, 1.05])\n",
    "    # ax.set_ylabel('Loss ({})'.format(net.loss_type))\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('# Batches')\n",
    "    plt.savefig(f\"./multiple_tasks/loss_{hyp_dict['ruleset']}_seed{seed}_{hyp_dict['addon_name']}.png\", dpi=1000)\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544aca8-271f-49d3-9ed3-ab7023f23600",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    net_helpers.net_eta_lambda_analysis(net, net_params, hyp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c10ab17-bab6-4228-9096-af042e9ac385",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_finalstage = False\n",
    "if use_finalstage:\n",
    "    # plotting output in the validation set\n",
    "    net_out, db = net.iterate_sequence_batch(test_input, run_mode='track_states')\n",
    "    W_output = net.W_output.detach().cpu().numpy()\n",
    "\n",
    "    W_all_ = []\n",
    "    for i in range(len(net.mp_layers)):\n",
    "        W_all_.append(net.mp_layers[i].W.detach().cpu().numpy())\n",
    "    W_ = W_all_[0]\n",
    "    \n",
    "else:\n",
    "    ind = len(marker_lst)-1 \n",
    "    # ind = 0\n",
    "    network_at_percent = (marker_lst[ind]+1)/train_params['n_datasets']*100\n",
    "    print(f\"Using network at {network_at_percent}%\")\n",
    "    # by default using the first test_input \n",
    "    net_out = netout_lst[0][ind]\n",
    "    db = db_lst[0][ind]\n",
    "    W_output = Woutput_lst[ind]\n",
    "    W_ = Wall_lst[ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8feb8c0-4029-49b1-b6e9-a5fd01ab5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_output(test_input_np, net_out, test_output_np, test_task=None, tag=\"\", batch_num=5):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    test_input_np = helper.to_ndarray(test_input_np)\n",
    "    net_out = helper.to_ndarray(net_out)\n",
    "    test_output_np = helper.to_ndarray(test_output_np)\n",
    "    \n",
    "    fig_all, axs_all = plt.subplots(batch_num,2,figsize=(4*2,batch_num*2))\n",
    "    \n",
    "    if test_output_np.shape[-1] == 1:\n",
    "        for batch_idx, ax in enumerate(axs):\n",
    "            ax.plot(net_out[batch_idx, :, 0], color=c_vals[batch_idx])\n",
    "            ax.plot(test_output_np[batch_idx, :, 0], color=c_vals_l[batch_idx])\n",
    "    \n",
    "    else:\n",
    "        for batch_idx in range(batch_num):\n",
    "            for out_idx in range(test_output_np.shape[-1]):\n",
    "                axs_all[batch_idx,0].plot(net_out[batch_idx, :, out_idx], color=c_vals[out_idx], label=out_idx)\n",
    "                axs_all[batch_idx,0].plot(test_output_np[batch_idx, :, out_idx], color=c_vals_l[out_idx], linewidth=5, alpha=0.5)\n",
    "                if test_task is not None: \n",
    "                    axs_all[batch_idx,0].set_title(f\"{task_params['rules'][test_task[batch_idx]]}\")\n",
    "                # axs_all[batch_idx,0].legend()\n",
    "    \n",
    "            input_batch = test_input_np[batch_idx,:,:]\n",
    "            if task_params[\"randomize_inputs\"]: \n",
    "                input_batch = input_batch @ np.linalg.pinv(task_params[\"randomize_matrix\"])\n",
    "            for inp_idx in range(input_batch.shape[-1]):\n",
    "                axs_all[batch_idx,1].plot(input_batch[:,inp_idx], color=c_vals[inp_idx], label=inp_idx)\n",
    "                if test_task is not None: \n",
    "                    axs_all[batch_idx,1].set_title(f\"{task_params['rules'][test_task[batch_idx]]}\")\n",
    "                # axs_all[batch_idx,1].legend()\n",
    "\n",
    "    for ax in axs_all.flatten(): \n",
    "        ax.set_ylim([-2, 2])\n",
    "    fig_all.tight_layout()\n",
    "    fig_all.savefig(f\"./multiple_tasks/lowD_{hyp_dict['ruleset']}_{hyp_dict['chosen_network']}_seed{seed}_{hyp_dict['addon_name']}_{tag}.png\", dpi=1000)\n",
    "\n",
    "plot_input_output(test_input_np, net_out, test_output_np, test_task, tag=\"\", batch_num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f92a0-c04f-4a7a-8b08-e753efb1b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here db is selected based on learning stage selection \n",
    "\n",
    "layer_index = 0 # 1 layer MPN \n",
    "if net_params[\"input_layer_add\"]:\n",
    "    layer_index += 1 \n",
    "    \n",
    "def modulation_extraction(test_input, db, layer_index):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    max_seq_len = test_input.shape[1] \n",
    "    n_batch_all_ = test_input.shape[0]\n",
    "    \n",
    "    Ms = np.concatenate((\n",
    "        db[f'M{layer_index}'].detach().cpu().numpy().reshape(n_batch_all_, max_seq_len, -1),\n",
    "    ), axis=-1)\n",
    "\n",
    "    Ms_orig = np.concatenate((\n",
    "        db[f'M{layer_index}'].detach().cpu().numpy(),\n",
    "    ), axis=-1)\n",
    "\n",
    "    bs = np.concatenate((\n",
    "        db[f'b{layer_index}'].detach().cpu().numpy(),\n",
    "    ), axis=-1) \n",
    "\n",
    "    hs = np.concatenate((\n",
    "        db[f'hidden{layer_index}'].detach().cpu().numpy().reshape(n_batch_all_, max_seq_len, -1),\n",
    "    ), axis=-1)\n",
    "\n",
    "    return Ms, Ms_orig, hs, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dbf3e8-cd24-4cca-9ff3-31140e83e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rules_epochs)\n",
    "all_rules = task_params[\"rules\"]\n",
    "print(all_rules)\n",
    "test_task = np.array(test_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b170e5bb-a866-40cd-8426-f62f6f364b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms, Ms_orig, hs, bs = modulation_extraction(test_input, db_lst[0][-1], layer_index)\n",
    "print(hs.shape)\n",
    "\n",
    "# in order of appearance\n",
    "# phase_to_indices = [\n",
    "#     (\"stim1\",  [0, 1, 4, 5, 6, 7]),\n",
    "#     (\"stim2\",  [6, 7]),\n",
    "#     (\"delay1\", [4, 5, 6, 7]),\n",
    "#     (\"delay2\", [6, 7]),\n",
    "#     (\"go1\",    [0, 1, 2, 3, 4, 5, 6, 7])\n",
    "# ]\n",
    "\n",
    "phase_to_indices = [\n",
    "    (\"stim1\",  [0, 1, 2, 3, 4]),\n",
    "    (\"stim2\",  [0, 1, 2, 3, 4]),\n",
    "    (\"delay1\", [0, 1, 2, 3, 4]),\n",
    "    (\"delay2\", [0, 1, 2, 3, 4]),\n",
    "    (\"go1\",    [0, 1, 2, 3, 4])\n",
    "]\n",
    "\n",
    "tb_break = [\n",
    "    [idx, rules_epochs[all_rules[idx]][phase]]\n",
    "    for phase, indices in phase_to_indices\n",
    "    for idx in indices\n",
    "]\n",
    "\n",
    "tb_break_name = [\n",
    "    f\"{all_rules[idx]}-{phase}\"\n",
    "    for phase, indices in phase_to_indices\n",
    "    for idx in indices\n",
    "]\n",
    "\n",
    "\n",
    "tb_break_name = np.array(tb_break_name)\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(12,4*2))\n",
    "\n",
    "cell_vars_rules = [] \n",
    "\n",
    "for el in range(len(tb_break)):\n",
    "    n_rules = len(task_params['rules'])\n",
    "    n_cells = hs.shape[-1]\n",
    "    \n",
    "    # cell_vars_rules = np.zeros((n_rules, n_cells,)) \n",
    "    \n",
    "    rule_idx, period_time = tb_break[el][0], tb_break[el][1]\n",
    "    \n",
    "    print('Rule {} (idx {})'.format(all_rules[rule_idx], rule_idx))\n",
    "    rule_hs = hs[test_task == rule_idx, period_time[0]:period_time[1], :]\n",
    "    print(np.max(np.var(rule_hs, axis=(0, 1))))\n",
    "    cell_vars_rules.append(np.var(rule_hs, axis=(0, 1))) \n",
    "\n",
    "cell_vars_rules = np.array(cell_vars_rules)\n",
    "print(cell_vars_rules.shape)\n",
    "\n",
    "cell_vars_rules_norm = np.zeros_like(cell_vars_rules)\n",
    "\n",
    "# normalize\n",
    "cell_max_var = np.max(cell_vars_rules, axis=0) # Across rules\n",
    "for period_idx in range(len(tb_break)):\n",
    "    cell_vars_rules_norm[period_idx] = np.where(\n",
    "        cell_max_var > 0., cell_vars_rules[period_idx] / cell_max_var, 0.\n",
    "    )\n",
    "\n",
    "# build rule-wise value lists and corresponding field names dynamically\n",
    "rule_vals  = [cell_vars_rules_norm[i].tolist() for i in range(n_rules)]\n",
    "rule_names = [f\"rule{i}\" for i in range(n_rules)]\n",
    "\n",
    "# structured array whose fields are rule0, rule1, , rule{n_rules-1}\n",
    "dtype = np.dtype([(name, float) for name in rule_names])\n",
    "rules_struct = np.array(list(zip(*rule_vals)), dtype=dtype)\n",
    "\n",
    "# descending lexicographic sort across all rule columns\n",
    "sort_idxs = np.argsort(rules_struct, order=rule_names)[::-1]\n",
    "\n",
    "# sort it \n",
    "cell_vars_rules_sorted_norm = cell_vars_rules_norm[:, sort_idxs]\n",
    "\n",
    "for period_idx in range(cell_vars_rules_sorted_norm.shape[0]): \n",
    "    ax[0].plot(cell_vars_rules_sorted_norm[period_idx], color=c_vals[period_idx],\n",
    "            label=tb_break_name[period_idx])\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel('Cell_idx')\n",
    "ax[0].set_ylabel('Normalized task variance')\n",
    "\n",
    "sns.heatmap(cell_vars_rules_sorted_norm, ax=ax[1], cmap=\"coolwarm\", cbar=True, vmin=0, vmax=1)\n",
    "ax[1].set_yticks(np.arange(len(tb_break_name)) + 0.5)\n",
    "ax[1].set_yticklabels(tb_break_name, rotation=45)\n",
    "ax[1].set_xlabel('Cell idx')\n",
    "\n",
    "fig.savefig(f\"./multiple_tasks/hidden_variance_{hyp_dict['ruleset']}_seed{seed}_{hyp_dict['addon_name']}.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e470b72c-1ea5-4082-9ab9-bc952dcf2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram, optimal_leaf_ordering\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def _hierarchical_clustering(data, k_min=3, k_max=40, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Hierarchical Ward clustering on `data` (observations  features).\n",
    "    \"\"\"\n",
    "    n_obs = data.shape[0]\n",
    "\n",
    "    pairwise_dists = pdist(data, metric=metric)\n",
    "    Z = linkage(pairwise_dists, method=\"ward\")\n",
    "    Z = optimal_leaf_ordering(Z, pairwise_dists)\n",
    "\n",
    "    best_k, best_score, best_labels = None, -np.inf, None\n",
    "    k_range = range(max(k_min, 2), min(k_max, n_obs - 1) + 1)\n",
    "    D_square = squareform(pairwise_dists)\n",
    "\n",
    "    for k in k_range:\n",
    "        labels = fcluster(Z, k, criterion=\"maxclust\")\n",
    "        score = silhouette_score(D_square, labels, metric=\"precomputed\")\n",
    "        if score > best_score:\n",
    "            best_k, best_score, best_labels = k, score, labels\n",
    "\n",
    "    leaf_order = dendrogram(Z, no_plot=True)[\"leaves\"]\n",
    "\n",
    "    return dict(\n",
    "        linkage=Z,\n",
    "        leaf_order=leaf_order,\n",
    "        labels=best_labels,\n",
    "        k=best_k,\n",
    "        silhouette=best_score,\n",
    "    )\n",
    "\n",
    "\n",
    "def cluster_variance_matrix(V, k_min=3, k_max=40):\n",
    "    \"\"\"\n",
    "    Cluster a variance matrix V (shape: N features  M neurons)\n",
    "    for both rows and columns.\n",
    "    \"\"\"\n",
    "    V = np.asarray(V)\n",
    "\n",
    "    row_res = _hierarchical_clustering(V,  k_min, k_max)\n",
    "    col_res = _hierarchical_clustering(V.T, k_min, k_max)\n",
    "\n",
    "    return dict(\n",
    "        row_order=row_res[\"leaf_order\"],\n",
    "        col_order=col_res[\"leaf_order\"],\n",
    "        row_labels=row_res[\"labels\"],\n",
    "        col_labels=col_res[\"labels\"],\n",
    "        row_k=row_res[\"k\"],\n",
    "        col_k=col_res[\"k\"],\n",
    "        row_linkage=row_res[\"linkage\"],   # full row hierarchy\n",
    "        col_linkage=col_res[\"linkage\"],   # full column hierarchy\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47aacc0-d4d3-4b17-aeec-1ea0ff31c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cluster_variance_matrix(cell_vars_rules_sorted_norm)\n",
    "cell_vars_rules_sorted_norm_ordered = cell_vars_rules_sorted_norm[np.ix_(result[\"row_order\"], result[\"col_order\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9771191-9cb1-4ad2-a670-a230e5614cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,figsize=(12,4*2))\n",
    "sns.heatmap(cell_vars_rules_sorted_norm, ax=ax[0], cmap=\"coolwarm\", cbar=True, vmin=0, vmax=1)\n",
    "ax[0].set_yticks(np.arange(len(tb_break_name))-0.5)\n",
    "ax[0].set_yticklabels(tb_break_name, rotation=45)\n",
    "sns.heatmap(cell_vars_rules_sorted_norm_ordered, ax=ax[1], cmap=\"coolwarm\", cbar=True, vmin=0, vmax=1)\n",
    "ax[1].set_yticks(np.arange(len(tb_break_name))-0.5)\n",
    "ax[1].set_yticklabels(tb_break_name[result[\"row_order\"]], rotation=45)\n",
    "fig.savefig(f\"./multiple_tasks/hidden_variance_cluster_{hyp_dict['ruleset']}_seed{seed}_{hyp_dict['addon_name']}.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b189f0-c14e-4527-af3b-1a57534fdcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"row_linkage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8843b-e5f8-4524-9735-e05092b9f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_break_name\n",
    "print(len(result[\"row_linkage\"]))\n",
    "print(len(result[\"col_linkage\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fc1bb2-f9df-4e97-88c0-8214c5deba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(15*2,4))\n",
    "dendrogram(result[\"row_linkage\"], ax=axs[0], labels=tb_break_name, leaf_rotation=45)\n",
    "axs[0].set_title(f\"Row hierarchy (k = {result['row_k']})\")\n",
    "\n",
    "dendrogram(result[\"col_linkage\"], ax=axs[1], labels=np.array([i for i in range(cell_vars_rules_sorted_norm_ordered.shape[1])]), leaf_rotation=45)\n",
    "axs[1].set_title(f\"Col hierarchy (k = {result['col_k']})\")\n",
    "fig.savefig(f\"./multiple_tasks/hidden_variance_hierarchy_{hyp_dict['ruleset']}_seed{seed}_{hyp_dict['addon_name']}.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad6b702-b4e0-4177-9233-de7d99462256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192dc0e-0021-446d-8e39-8da925909b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
