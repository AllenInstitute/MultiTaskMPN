{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374fb8f2-9b83-44ce-821b-8917a114c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os \n",
    "\n",
    "# PyTorch Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data Handling and Image Processing\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Style for Matplotlib\n",
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.style.use(['no-latex'])\n",
    "\n",
    "# Scientific Computing and Machine Learning\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.linalg import subspace_angles\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Custom Modules and Extensions\n",
    "sys.path.append(\"../netrep/\")\n",
    "sys.path.append(\"../svcca/\")\n",
    "\n",
    "import networks as nets  # Contains RNNs\n",
    "import net_helpers\n",
    "import mpn_tasks\n",
    "import helper\n",
    "import mpn\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use('science')\n",
    "plt.style.use(['no-latex'])\n",
    "\n",
    "# Memory Optimization\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1556c8-a4b6-434b-a60f-37035980bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 Red, 1 blue, 2 green, 3 purple, 4 orange, 5 teal, 6 gray, 7 pink, 8 yellow\n",
    "c_vals = ['#e53e3e', '#3182ce', '#38a169', '#805ad5','#dd6b20', '#319795', '#718096', '#d53f8c', '#d69e2e',]\n",
    "c_vals_l = ['#feb2b2', '#90cdf4', '#9ae6b4', '#d6bcfa', '#fbd38d', '#81e6d9', '#e2e8f0', '#fbb6ce', '#faf089',]\n",
    "c_vals_d = ['#9b2c2c', '#2c5282', '#276749', '#553c9a', '#9c4221', '#285e61', '#2d3748', '#97266d', '#975a16',]\n",
    "l_vals = ['solid', 'dashed', 'dotted', 'dashdot', '-', '--', '-.', ':', (0, (3, 1, 1, 1)), (0, (5, 10))]\n",
    "markers_vals = ['o', 'v', '^', '<', '>', '1', '2', '3', '4', 's', 'p', '*', 'h', 'H', '+', 'x', 'D', 'd', '|', '_']\n",
    "hyp_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34978bf6-67b8-41bd-a022-a7b46a320686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set seed 33\n",
      "Fixation_off: True; Task_info: True\n",
      "Rules: ['delaydm1']\n",
      "  Input size 7, Output size 3\n",
      "Using CUDA...\n"
     ]
    }
   ],
   "source": [
    "# Reload modules if changes have been made to them\n",
    "from importlib import reload\n",
    "\n",
    "reload(nets)\n",
    "reload(net_helpers)\n",
    "\n",
    "fixseed = False # randomize setting the seed may lead to not perfectly solved results\n",
    "seed = random.randint(1,1000) if not fixseed else 8 # random set the seed to test robustness by default\n",
    "print(f\"Set seed {seed}\")\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "hyp_dict['task_type'] = 'multitask' # int, NeuroGym, multitask\n",
    "hyp_dict['mode_for_all'] = \"random_batch\"\n",
    "hyp_dict['ruleset'] = 'delaydm1' # low_dim, all, test\n",
    "\n",
    "accept_rules = ('fdgo', 'fdanti', 'delaygo', 'delayanti', 'reactgo', 'reactanti', \n",
    "                'delaydm1', 'delaydm2', 'dmsgo', 'dmcgo', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm', 'dm1')\n",
    "\n",
    "\n",
    "rules_dict = \\\n",
    "    {'all' : ['fdgo', 'reactgo', 'delaygo', 'fdanti', 'reactanti', 'delayanti',\n",
    "              'dm1', 'dm2', 'contextdm1', 'contextdm2', 'multidm',\n",
    "              'delaydm1', 'delaydm2', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm',\n",
    "              'dmsgo', 'dmsnogo', 'dmcgo', 'dmcnogo'],\n",
    "     'low_dim' : ['fdgo', 'reactgo', 'delaygo', 'fdanti', 'reactanti', 'delayanti',\n",
    "                 'delaydm1', 'delaydm2', 'contextdelaydm1', 'contextdelaydm2', 'multidelaydm',\n",
    "                 'dmsgo', 'dmsnogo', 'dmcgo', 'dmcnogo'],\n",
    "\n",
    "     'gofamily': ['fdgo', 'fdanti', 'reactgo', 'reactanti', 'delaygo', 'delayanti'],\n",
    "\n",
    "     'delaygo': ['delaygo'],\n",
    "     'delaygofamily': ['delaygo', 'delayanti'],\n",
    "     'fdgo': ['fdgo'],\n",
    "     'fdfamily': ['fdgo', 'fdanti'],\n",
    "     'reactgo': ['reactgo'],\n",
    "     'reactfamily': ['reactgo', 'reactanti'],\n",
    "     \n",
    "     'delaydm1': ['delaydm1'],\n",
    "     'delaydmfamily': ['delaydm1', 'delaydm2'],\n",
    "     \n",
    "     'dmsgofamily': ['dmsgo', 'dmsnogo'],\n",
    "     'dmsgo': ['dmsgo'],\n",
    "     'dmcgo': ['dmcgo'],\n",
    "     'contextdelaydm1': ['contextdelaydm1'], \n",
    "     'contextdelayfamily': ['contextdelaydm1', 'contextdelaydm2'],\n",
    "    }\n",
    "    \n",
    "\n",
    "# This can either be used to set parameters OR set parameters and train\n",
    "train = True # whether or not to train the network\n",
    "verbose = True\n",
    "hyp_dict['run_mode'] = 'minimal' # minimal, debug\n",
    "hyp_dict['chosen_network'] = \"dmpn\"\n",
    "\n",
    "# suffix for saving images\n",
    "hyp_dict['addon_name'] = \"\"\n",
    "\n",
    "mpn_depth = 1\n",
    "\n",
    "# for coding \n",
    "if hyp_dict['chosen_network'] in (\"gru\", \"vanilla\"):\n",
    "    mpn_depth = 1\n",
    "\n",
    "def current_basic_params():\n",
    "    task_params = {\n",
    "        'task_type': hyp_dict['task_type'],\n",
    "        'rules': rules_dict[hyp_dict['ruleset']],\n",
    "        'dt': 40, # ms, directly influence sequence lengths,\n",
    "        'ruleset': hyp_dict['ruleset'],\n",
    "        'n_eachring': 8, # Number of distinct possible inputs on each ring\n",
    "        'in_out_mode': 'low_dim',  # high_dim or low_dim or low_dim_pos (Robert vs. Laura's onetask, resp)\n",
    "        'sigma_x': 0.00, # Laura raised to 0.1 to prevent overfitting (Robert uses 0.01)\n",
    "        'mask_type': 'cost', # 'cost', None\n",
    "        'fixate_off': True, # Second fixation signal goes on when first is off\n",
    "        'task_info': True, \n",
    "        'randomize_inputs': False,\n",
    "        'n_input': 20, # Only used if inputs are randomized,\n",
    "        'modality_diff': False, # if two stimulus are included in the task, put them into different modality,\n",
    "        'label_strength': False,\n",
    "        'long_fixation': 'normal', \n",
    "        'long_stimulus': 'normal',\n",
    "        'long_delay': 'normal',\n",
    "        'long_response': 'normal',\n",
    "        'adjust_task_prop': True,\n",
    "        'adjust_task_decay': 0.9, \n",
    "    }\n",
    "\n",
    "    print(f\"Fixation_off: {task_params['fixate_off']}; Task_info: {task_params['task_info']}\")\n",
    "\n",
    "    train_params = {\n",
    "        'lr': 1e-3,\n",
    "        'n_batches': 128,\n",
    "        'batch_size': 128,\n",
    "        'gradient_clip': 10,\n",
    "        'valid_n_batch': 500,\n",
    "        'n_datasets': 5000, # Number of distinct batches\n",
    "        'valid_check': None, \n",
    "        'n_epochs_per_set': 1, # longer/shorter training\n",
    "        'task_mask': None, # None, task\n",
    "        'weight_reg': 'L2',\n",
    "        'reg_lambda': 1e-4,\n",
    "    }\n",
    "\n",
    "    if not train: # some \n",
    "        assert train_params['n_epochs_per_set'] == 0\n",
    "\n",
    "    n_hidden = 200\n",
    "    linear_embed = 200\n",
    "\n",
    "    net_params = {\n",
    "        'net_type': hyp_dict['chosen_network'], # mpn1, dmpn, vanilla\n",
    "        'n_neurons': [1] + [n_hidden] * mpn_depth + [1],\n",
    "        'linear_embed': linear_embed, \n",
    "        'output_bias': False, # Turn off biases for easier interpretation\n",
    "        'loss_type': 'MSE', # XE, MSE\n",
    "        'activation': 'tanh', # linear, ReLU, sigmoid, tanh, tanh_re, tukey, heaviside\n",
    "        'cuda': True,\n",
    "        'monitor_freq': train_params[\"n_epochs_per_set\"],\n",
    "        'monitor_valid_out': True, # Whether or not to save validation output throughout training\n",
    "        'output_matrix': '',# \"\" (default); \"untrained\", or \"orthogonal\"\n",
    "        'input_layer_add': True, # for one-task, probably no need to have input layer added\n",
    "        'input_layer_add_trainable': False, # revise this is effectively to [randomize_inputs], tune this\n",
    "        'input_layer_bias': False, \n",
    "        'input_layer': \"trainable\", # for RNN only\n",
    "        \"tbptt\": True, # for local learning? \n",
    "        'acc_measure': 'stimulus', \n",
    "        \n",
    "        'ml_params': {\n",
    "            'bias': True, # Bias of layer\n",
    "            'mp_type': 'mult',\n",
    "            'm_update_type': 'hebb_assoc', # hebb_assoc, hebb_pre\n",
    "            'eta_type': 'scalar', # scalar, pre_vector, post_vector, matrix\n",
    "            'eta_train': True,\n",
    "            # 'eta_init': 'gaussian', \n",
    "            'lam_type': 'scalar', # scalar, pre_vector, post_vector, matrix\n",
    "            'm_time_scale': 400, # ms, sets lambda\n",
    "            'lam_train': False,\n",
    "            'W_freeze': False  \n",
    "        },\n",
    "\n",
    "        # Vanilla RNN params\n",
    "        'leaky': True,\n",
    "        'alpha': 0.2,\n",
    "    }\n",
    "        \n",
    "    return task_params, train_params, net_params\n",
    "\n",
    "task_params, train_params, net_params = current_basic_params()\n",
    "\n",
    "shift_index = 1 if not task_params['fixate_off'] else 0\n",
    "\n",
    "if hyp_dict['task_type'] in ('multitask',):\n",
    "    task_params, train_params, net_params = mpn_tasks.convert_and_init_multitask_params(\n",
    "        (task_params, train_params, net_params)\n",
    "    )\n",
    "\n",
    "    net_params['prefs'] = mpn_tasks.get_prefs(task_params['hp'])\n",
    "\n",
    "    print('Rules: {}'.format(task_params['rules']))\n",
    "    print('  Input size {}, Output size {}'.format(\n",
    "        task_params['n_input'], task_params['n_output'],\n",
    "    ))\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "if net_params['cuda']:\n",
    "    print('Using CUDA...')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('Using CPU...')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a341b36-dc7a-42b0-bffb-cb17d380041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_dict[\"mess_with_training\"] = False\n",
    "\n",
    "if hyp_dict['mess_with_training']:\n",
    "    hyp_dict['addon_name'] += \"messwithtraining\"\n",
    "\n",
    "params = task_params, train_params, net_params\n",
    "\n",
    "# random matrix\n",
    "random_matrix = None\n",
    "if task_params[\"randomize_inputs\"]:\n",
    "    random_matrix = task_params[\"randomize_matrix\"]\n",
    "\n",
    "if net_params['net_type'] == 'mpn1':\n",
    "    netFunction = mpn.MultiPlasticNet\n",
    "elif net_params['net_type'] == 'dmpn':\n",
    "    netFunction = mpn.DeepMultiPlasticNet\n",
    "elif net_params['net_type'] == 'vanilla':\n",
    "    netFunction = nets.VanillaRNN\n",
    "elif net_params['net_type'] == 'gru':\n",
    "    netFunction = nets.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07e4fe48-2af6-4741-8d42-01803ba0abf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align ['delaydm1'] With Same Time\n",
      "delaydm1\n",
      "torch.Size([500, 59, 7])\n"
     ]
    }
   ],
   "source": [
    "test_n_batch = train_params[\"valid_n_batch\"]\n",
    "color_by = \"stim\"\n",
    "\n",
    "task_random_fix = True\n",
    "if task_random_fix:\n",
    "    print(f\"Align {task_params['rules']} With Same Time\")\n",
    "\n",
    "if task_params['task_type'] in ('multitask',): # Test batch consists of all the rules\n",
    "    task_params['hp']['batch_size_train'] = test_n_batch\n",
    "    # using homogeneous cutting off\n",
    "    test_mode_for_all = \"random\"\n",
    "    # ZIHAN\n",
    "    # generate test data using \"random\"\n",
    "    test_data, test_trials_extra = mpn_tasks.generate_trials_wrap(task_params, test_n_batch, \\\n",
    "                rules=task_params['rules'], mode_input=test_mode_for_all, fix=task_random_fix)\n",
    "    _, test_trials, test_rule_idxs = test_trials_extra\n",
    "\n",
    "    task_params['dataset_name'] = 'multitask'\n",
    "\n",
    "    if task_params['in_out_mode'] in ('low_dim_pos',):\n",
    "        output_dim_labels = ('Fixate', 'Cos', '-Cos', 'Sin', '-Sin')\n",
    "    elif task_params['in_out_mode'] in ('low_dim',):\n",
    "        output_dim_labels = ('Fixate', 'Cos', 'Sin')\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    labels = []\n",
    "    for rule_idx, rule in enumerate(task_params['rules']):\n",
    "        print(rule)\n",
    "        if rule in accept_rules:\n",
    "            if hyp_dict['ruleset'] in ('dmsgo', 'dmcgo'):\n",
    "                labels.append(test_trials[rule_idx].meta['matches'])\n",
    "            else:\n",
    "                labels.append(test_trials[rule_idx].meta['resp1' if color_by == \"resp\" else 'stim1'])\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    labels = np.concatenate(labels, axis=0).reshape(-1,1)\n",
    "\n",
    "test_input, test_output, test_mask = test_data\n",
    "\n",
    "permutation = np.random.permutation(test_input.shape[0])\n",
    "test_input = test_input[permutation]\n",
    "test_output = test_output[permutation]\n",
    "test_mask = test_mask[permutation]\n",
    "labels = labels[permutation]\n",
    "\n",
    "test_input_np = test_input.detach().cpu().numpy()\n",
    "test_output_np = test_output.detach().cpu().numpy()\n",
    "\n",
    "n_batch_all = test_input_np.shape[0] # Total number of batches, might be different than test_n_batch\n",
    "max_seq_len = test_input_np.shape[1]\n",
    "\n",
    "if task_params[\"randomize_inputs\"]: \n",
    "    rmat = task_params[\"randomize_matrix\"]\n",
    "    test_input_np = np.matmul(test_input_np, np.linalg.pinv(rmat))\n",
    "\n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e78b44e9-b6e3-4c1c-a5c7-5a608a6d090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiPlastic Net:\n",
      "  output neurons: 3\n",
      "  Act: tanh\n",
      "\n",
      "  Input Layer Frozen.\n",
      "  MP Layer1 parameters:\n",
      "    n_neurons - input: 100, output: 200\n",
      "    M matrix parameters:    update bounds - Max mult: 1.0, Min mult: -1.0\n",
      "      type: mult // Update - type: hebb_assoc // Act fn: linear\n",
      "      Eta: scalar (train) // Lambda: scalar (fixed) // Lambda_max: 0.90 (tau: 4.0e+02)\n",
      "  MP Layer2 parameters:\n",
      "    n_neurons - input: 200, output: 200\n",
      "    M matrix parameters:    update bounds - Max mult: 1.0, Min mult: -1.0\n",
      "      type: mult // Update - type: hebb_assoc // Act fn: linear\n",
      "      Eta: scalar (train) // Lambda: scalar (fixed) // Lambda_max: 0.90 (tau: 4.0e+02)\n",
      "  MP Layer3 parameters:\n",
      "    n_neurons - input: 200, output: 200\n",
      "    M matrix parameters:    update bounds - Max mult: 1.0, Min mult: -1.0\n",
      "      type: mult // Update - type: hebb_assoc // Act fn: linear\n",
      "      Eta: scalar (train) // Lambda: scalar (fixed) // Lambda_max: 0.90 (tau: 4.0e+02)\n",
      "  No Hidden Recurrency.\n",
      "Trainable parameters: 101,203\n",
      "W_output: (3, 200)\n",
      "mp_layer1.W: (200, 100)\n",
      "mp_layer1.b: (200,)\n",
      "mp_layer1.eta: ()\n",
      "mp_layer2.W: (200, 200)\n",
      "mp_layer2.b: (200,)\n",
      "mp_layer2.eta: ()\n",
      "mp_layer3.W: (200, 200)\n",
      "mp_layer3.b: (200,)\n",
      "mp_layer3.eta: ()\n",
      "task_params['rules_probs']: [1.]\n",
      "Rule: delaydm1\n",
      "Rule delaydm1 seq_len 137, max_seq_len 137\n",
      "inputs_all paddled: (128, 137, 7)\n",
      "inputs_all: torch.Size([128, 137, 7])\n",
      "========== Setup Parameters ==========\n",
      "Train parameters:\n",
      "  Loss: MSE // LR: 1.00e-03 // Optim: adam\n",
      "  Grad type: backprop // Gradient clip: 1.0e+01\n",
      "Weight reg: L2, coef: 1.0e-04\n",
      "Activity reg: None\n",
      "valid_acc_history: [None, None, None, None]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# we use net at different training stage on the same test_input\u001b[39;00m\n\u001b[1;32m      2\u001b[0m net, _, (counter_lst, netout_lst, db_lst, Winput_lst, Winputbias_lst, \\\n\u001b[0;32m----> 3\u001b[0m          Woutput_lst, Wall_lst, marker_lst, loss_lst, acc_lst), _ \u001b[38;5;241m=\u001b[39m \u001b[43mnet_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                                                           \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                                                           \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                                                           \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                                                           \u001b[49m\u001b[43mhyp_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyp_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                                                           \u001b[49m\u001b[43mnetFunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                                                           \u001b[49m\u001b[43mtest_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                                                           \u001b[49m\u001b[43mprint_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/allen/programs/mindscope/workgroups/auto-model/zihan.zhang/MultiTaskMPN/net_helpers.py:425\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(params, net, device, verbose, train, hyp_dict, netFunction, test_input, pretraining_shift, pretraining_shift_pre, print_frequency)\u001b[0m\n\u001b[1;32m    422\u001b[0m     Wall_lst\u001b[38;5;241m.\u001b[39mappend(W_all_)\n\u001b[1;32m    423\u001b[0m     marker_lst\u001b[38;5;241m.\u001b[39mappend(dataset_idx)\n\u001b[0;32m--> 425\u001b[0m _, monitor_loss, monitor_acc, goodness_history, valid_acc_history \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_trails\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m                                                                            \u001b[49m\u001b[43mvalid_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_trails\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_trails\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m                                                                            \u001b[49m\u001b[43mnew_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_thresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyp_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun_mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatanum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_idx \u001b[38;5;241m%\u001b[39m GLOBAL_PRINT_FREQUENCY \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[1;32m    430\u001b[0m     \u001b[38;5;66;03m# 2025-11-13: we should consider loss temporal convolution with various decay factor\u001b[39;00m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# to make sure the network has good performance across different levels\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# i.e. if decay_factor is 1.00, equally focusing across the temporal window\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;66;03m# if decay_factor < 1.00, then allow gradual weight decaying for the past history\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_acc_history: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_acc_history\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/allen/programs/mindscope/workgroups/auto-model/zihan.zhang/MultiTaskMPN/net_helpers.py:1125\u001b[0m, in \u001b[0;36mBaseNetwork.fit\u001b[0;34m(self, train_params, train_data, train_trails, valid_batch, valid_trails, new_thresh, run_mode, datanum)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m# put in train mode (doesn't really do anything unless we are using dropout/batch norm)\u001b[39;00m\n\u001b[0;32m-> 1125\u001b[0m db, monitor_loss, monitor_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_trails\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mvalid_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mvalid_trails\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_trails\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mnew_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_thresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatanum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatanum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m last_group_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup_valid_acc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m   1132\u001b[0m last_group_goodness \u001b[38;5;241m=\u001b[39m mpn_tasks\u001b[38;5;241m.\u001b[39mnormalize_to_one([\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m acc \u001b[38;5;28;01mfor\u001b[39;00m acc \u001b[38;5;129;01min\u001b[39;00m last_group_acc])\n",
      "File \u001b[0;32m/allen/programs/mindscope/workgroups/auto-model/zihan.zhang/MultiTaskMPN/net_helpers.py:1262\u001b[0m, in \u001b[0;36mBaseNetwork.train_epochs\u001b[0;34m(self, train_params, train_data, train_trails, valid_batch, valid_trails, new_thresh, monitor, run_mode, datanum)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Note this will always be one more than corresponding seq_idx\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m monitor \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor_freq, \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;66;03m# Do a monitor for a set amount of iterations\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m                     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_monitor \u001b[38;5;129;01mand\u001b[39;00m seq_idx \u001b[38;5;241m==\u001b[39m train_inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)): \u001b[38;5;66;03m# Do one monitor at the end of train set\u001b[39;00m\n\u001b[0;32m-> 1262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_monitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_masks_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_go_info_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_go_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m                      \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mvalid_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnowiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;66;03m# At the end of the epoch, shuffle over batch dimension\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m train_inputs, train_labels, train_masks \u001b[38;5;241m=\u001b[39m shuffle_dataset(\n\u001b[1;32m   1268\u001b[0m     train_inputs, train_labels, train_masks\n\u001b[1;32m   1269\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/mpn/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/allen/programs/mindscope/workgroups/auto-model/zihan.zhang/MultiTaskMPN/mpn.py:523\u001b[0m, in \u001b[0;36mMultiPlasticNetBase._monitor\u001b[0;34m(self, train_batch, train_go_info_batch, valid_go_info_batch, train_type, output, loss, loss_components, acc, valid_batch, nowiter)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_monitor\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_batch, train_go_info_batch, valid_go_info_batch, train_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupervised\u001b[39m\u001b[38;5;124m'\u001b[39m, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, loss_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    521\u001b[0m              acc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, valid_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, nowiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_monitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_go_info_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_go_info_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mvalid_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnowiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnowiter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mpl_idx, mp_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_layers):\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mp_layer\u001b[38;5;241m.\u001b[39mmp_layer_name)]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    528\u001b[0m             mp_layer\u001b[38;5;241m.\u001b[39meta\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    529\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/mpn/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/allen/programs/mindscope/workgroups/auto-model/zihan.zhang/MultiTaskMPN/net_helpers.py:1764\u001b[0m, in \u001b[0;36mBaseNetwork._monitor\u001b[0;34m(self, train_batch, train_go_info_batch, valid_go_info, output, loss, loss_components, valid_batch, nowiter)\u001b[0m\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;66;03m# print(f\"valid_inputs_batch.shape: {valid_inputs_batch.shape}\")\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1764\u001b[0m     valid_output, valid_hidden, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate_sequence_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_inputs_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor_valid_out: \u001b[38;5;66;03m# Saves validation output if needed\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_output\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(valid_output\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/allen/programs/mindscope/workgroups/auto-model/zihan.zhang/MultiTaskMPN/net_helpers.py:1324\u001b[0m, in \u001b[0;36mBaseNetwork.iterate_sequence_batch\u001b[0;34m(self, batch_inputs, batch_labels, batch_masks, run_mode, save_to_cpu, detach_saved, non_blocking)\u001b[0m\n\u001b[1;32m   1321\u001b[0m db_save_dev \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m (track \u001b[38;5;129;01mand\u001b[39;00m save_to_cpu) \u001b[38;5;28;01melse\u001b[39;00m compute_dev\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T):\n\u001b[0;32m-> 1324\u001b[0m     step_output, step_activity, db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Prepare what we store (detach + move if requested)\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m     out_to_store \u001b[38;5;241m=\u001b[39m step_output\n",
      "File \u001b[0;32m/allen/programs/mindscope/workgroups/auto-model/zihan.zhang/MultiTaskMPN/mpn.py:782\u001b[0m, in \u001b[0;36mDeepMultiPlasticNet.network_step\u001b[0;34m(self, current_input, run_mode, verbose, seq_idx)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m   Pre mean \u001b[39m\u001b[38;5;132;01m{:.2e}\u001b[39;00m\u001b[38;5;124m post mean \u001b[39m\u001b[38;5;132;01m{:.2e}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    776\u001b[0m             torch\u001b[38;5;241m.\u001b[39mmean(mpl_activities[mpl_idx]\u001b[38;5;241m.\u001b[39mdetach()), torch\u001b[38;5;241m.\u001b[39mmean(mpl_activities[mpl_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m    777\u001b[0m         ))\n\u001b[1;32m    778\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m   M mag mean \u001b[39m\u001b[38;5;132;01m{:.2e}\u001b[39;00m\u001b[38;5;124m max \u001b[39m\u001b[38;5;132;01m{:.2e}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    779\u001b[0m             torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(mp_layer\u001b[38;5;241m.\u001b[39mM\u001b[38;5;241m.\u001b[39mdetach())), torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mabs(mp_layer\u001b[38;5;241m.\u001b[39mM\u001b[38;5;241m.\u001b[39mdetach()))\n\u001b[1;32m    780\u001b[0m         ))\n\u001b[0;32m--> 782\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmp_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_M_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmpl_activities\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmpl_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmpl_activities\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmpl_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, mpl_activities, db\n",
      "File \u001b[0;32m/allen/programs/mindscope/workgroups/auto-model/zihan.zhang/MultiTaskMPN/mpn.py:334\u001b[0m, in \u001b[0;36mMultiPlasticLayer.update_M_matrix\u001b[0;34m(self, pre, post, update_mask)\u001b[0m\n\u001b[1;32m    331\u001b[0m     post \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(post\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(post)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_update_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhebb_assoc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhebb_pre\u001b[39m\u001b[38;5;124m'\u001b[39m,):\n\u001b[0;32m--> 334\u001b[0m     delta_M \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m M \u001b[38;5;241m+\u001b[39m lam\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m M \u001b[38;5;241m+\u001b[39m \u001b[43meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBi, BI -> BiI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_update_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moja\u001b[39m\u001b[38;5;124m'\u001b[39m,):\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeed to update to a batched version.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# we use net at different training stage on the same test_input\n",
    "net, _, (counter_lst, netout_lst, db_lst, Winput_lst, Winputbias_lst, \\\n",
    "         Woutput_lst, Wall_lst, marker_lst, loss_lst, acc_lst), _ = net_helpers.train_network(params, \n",
    "                                                                                           device=device, \n",
    "                                                                                           verbose=verbose, \n",
    "                                                                                           train=train, \n",
    "                                                                                           hyp_dict=hyp_dict, \n",
    "                                                                                           netFunction=netFunction, \n",
    "                                                                                           test_input=[test_input],\n",
    "                                                                                           print_frequency=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6856d2-8051-4bd0-87db-17457f116e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_parameters(model):\n",
    "    \"\"\"Return a list of (name, parameter) for trainable parameters.\"\"\"\n",
    "    return [(name) for name, p in model.named_parameters() if p.requires_grad]\n",
    "\n",
    "trainable_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47256480-5b47-496e-887e-b8de35dcc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    fig, ax = plt.subplots(1,1,figsize=(4,4))\n",
    "    ax.plot(net.hist['iters_monitor'][1:], net.hist['train_acc'][1:], color=c_vals[0], label='Full train accuracy')\n",
    "    ax.plot(net.hist['iters_monitor'][1:], net.hist['valid_acc'][1:], color=c_vals[1], label='Full valid accuracy')\n",
    "    if net.weight_reg is not None:\n",
    "        ax.plot(net.hist['iters_monitor'], net.hist['train_loss_output_label'], color=c_vals_l[0], zorder=-1, label='Output label')\n",
    "        ax.plot(net.hist['iters_monitor'], net.hist['train_loss_reg_term'], color=c_vals_l[0], zorder=-1, label='Reg term', linestyle='dashed')\n",
    "        ax.plot(net.hist['iters_monitor'], net.hist['valid_loss_output_label'], color=c_vals_l[1], zorder=-1, label='Output valid label')\n",
    "        ax.plot(net.hist['iters_monitor'], net.hist['valid_loss_reg_term'], color=c_vals_l[1], zorder=-1, label='Reg valid term', linestyle='dashed')\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_ylabel('Accuracy', fontsize=15)\n",
    "    ax.set_xlabel('# Batches', fontsize=15)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"./onetask/loss_{hyp_dict['ruleset']}_{task_params['fixate_off']}.png\")\n",
    "    \n",
    "print('Done!')\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544aca8-271f-49d3-9ed3-ab7023f23600",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    net_helpers.net_eta_lambda_analysis(net, net_params, hyp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b385cd9-3f03-4c33-a943-ef80ca4df69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyp_dict['chosen_network'] == \"dmpn\":\n",
    "    if net_params[\"input_layer_add\"]:\n",
    "        input_matrix = net.W_initial_linear.weight.data.detach().cpu().numpy()\n",
    "        figinp, axsinp = plt.subplots(1,1,figsize=(4,4))\n",
    "        sns.heatmap(input_matrix, ax=axsinp, square=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c10ab17-bab6-4228-9096-af042e9ac385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_finalstage = False\n",
    "if use_finalstage:\n",
    "    # plotting output in the validation set\n",
    "    net_out, db = net.iterate_sequence_batch(test_input, run_mode='track_states')\n",
    "    W_output = net.W_output.detach().cpu().numpy()\n",
    "\n",
    "    W_all_ = []\n",
    "    for i in range(len(net.mp_layers)):\n",
    "        W_all_.append(net.mp_layers[i].W.detach().cpu().numpy())\n",
    "    W_ = W_all_[0]\n",
    "    \n",
    "else:\n",
    "    ind = len(marker_lst)-1\n",
    "    # ind = 0\n",
    "    network_at_percent = (marker_lst[ind]+1)/train_params['n_datasets']*100\n",
    "    print(f\"Using network at {network_at_percent}%\")\n",
    "    net_out = netout_lst[0][ind]\n",
    "    db = db_lst[0][ind]\n",
    "    W_output = Woutput_lst[ind]\n",
    "    if net_params[\"net_type\"] == \"dmpn\":\n",
    "        W_ = Wall_lst[ind][0]\n",
    "\n",
    "if net_params['loss_type'] in ('MSE',):\n",
    "    fig, axs = plt.subplots(5, 1, figsize=(6, 3*5))\n",
    "    figin, axsin = plt.subplots(5, 1, figsize=(6, 3*5))\n",
    "\n",
    "    if test_output_np.shape[-1] == 1:\n",
    "        for batch_idx, ax in enumerate(axs):\n",
    "            ax.plot(net_out[batch_idx, :, 0], color=c_vals[batch_idx])\n",
    "            ax.plot(test_output_np[batch_idx, :, 0], color=c_vals_l[batch_idx])\n",
    "\n",
    "    else:\n",
    "        for batch_idx, ax in enumerate(axs):\n",
    "            task_label = test_input_np[batch_idx, 0, 6-shift_index:]\n",
    "            output_batch = net_out[batch_idx,:,:]\n",
    "            task_label_index = np.where(np.isclose(task_label, 1, atol=0.1))[0][0]\n",
    "            for out_idx in range(test_output_np.shape[-1]):\n",
    "                axs[batch_idx].plot(net_out[batch_idx,:,out_idx], color=c_vals[out_idx+3])\n",
    "                axs[batch_idx].plot(test_output_np[batch_idx,:,out_idx], color=c_vals_l[out_idx+3], \n",
    "                                    linewidth=5, alpha=0.5)\n",
    "            axs[batch_idx].set_ylim([-1.2, 1.2])\n",
    "            axs[batch_idx].set_xlabel(\"Time Steps\", fontsize=15)\n",
    "            axs[batch_idx].set_ylabel(\"Output Magnitude\", fontsize=15)\n",
    "\n",
    "            input_batch = test_input[batch_idx,:,:].cpu().numpy()\n",
    "            for inp_idx in range(input_batch.shape[-1]):\n",
    "                axsin[batch_idx].plot(input_batch[:,inp_idx], color=c_vals[inp_idx], label=inp_idx)\n",
    "            # axsin[batch_idx].legend()\n",
    "            axsin[batch_idx].set_ylim([-1.2, 1.2])\n",
    "            axsin[batch_idx].set_xlabel(\"Time Steps\", fontsize=15)\n",
    "            axsin[batch_idx].set_ylabel(\"Input Magnitude\", fontsize=15)\n",
    "\n",
    "    fig.suptitle(f\"Validation Set Output Comparison using Network at Percentage {network_at_percent}%\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"./onetask/lowD_{hyp_dict['ruleset']}_{hyp_dict['chosen_network']}_{hyp_dict['addon_name']}_seed{seed}.png\", dpi=300)\n",
    "\n",
    "    figin.suptitle(f\"Validation Set Output Comparison using Network at Percentage {network_at_percent}%\")\n",
    "    figin.tight_layout()\n",
    "    figin.savefig(f\"./onetask/lowD_{hyp_dict['ruleset']}_{hyp_dict['chosen_network']}_{hyp_dict['addon_name']}_input_seed{seed}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719a0a5-ac01-4064-bcc3-6296a240056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,figsize=(8,4*2))\n",
    "sns.heatmap(input_batch.T, ax=axs[0], cmap=\"coolwarm\")\n",
    "sns.heatmap(output_batch.T, ax=axs[1], cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efbd2f-a48d-4f8e-ba55-b0b102463546",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index = 0 # 1 layer MPN \n",
    "if net_params[\"input_layer_add\"]:\n",
    "    layer_index += 1 \n",
    "\n",
    "# here db is selected based on learning stage selection \n",
    "def modulation_extraction(db, max_seq_len, layer_index):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    n_batch_all_ = test_input.shape[0]\n",
    "    \n",
    "    Ms = np.concatenate((\n",
    "        db[f'M{layer_index}'].reshape(n_batch_all_, max_seq_len, -1),\n",
    "    ), axis=-1)\n",
    "\n",
    "    Ms_orig = np.concatenate((\n",
    "        db[f'M{layer_index}'],\n",
    "    ), axis=-1)\n",
    "\n",
    "    bs = np.concatenate((\n",
    "        db[f'b{layer_index}'],\n",
    "    ), axis=-1) \n",
    "\n",
    "    hs = np.concatenate((\n",
    "        db[f'hidden{layer_index}'].reshape(n_batch_all_, max_seq_len, -1),\n",
    "    ), axis=-1)\n",
    "\n",
    "    xs = np.concatenate((\n",
    "        db[f'input{layer_index}'].reshape(n_batch_all_, max_seq_len, -1),\n",
    "    ), axis=-1)\n",
    "\n",
    "    return Ms, Ms_orig, hs, bs, xs\n",
    "    \n",
    "if net_params[\"net_type\"] in (\"dmpn\", ):\n",
    "    if mpn_depth == 1:\n",
    "        Ms, Ms_orig, hs, bs, xs = modulation_extraction(db_lst[0][-1], max_seq_len, layer_index)\n",
    "        print(Ms_orig.shape)\n",
    "    else:\n",
    "        modulations, hiddens = [], []\n",
    "        for i in range(mpn_depth):\n",
    "            modulations.append(db[f'M{i}'].detach().cpu().numpy().reshape(n_batch_all, max_seq_len, -1))\n",
    "            hiddens.append(db[f'hidden{i}'].detach().cpu().numpy().reshape(n_batch_all, max_seq_len, -1),)\n",
    "\n",
    "        Ms = modulations[0]\n",
    "        hs = hiddens[0]\n",
    "        \n",
    "elif net_params[\"net_type\"] in (\"vanilla\", \"gru\"):\n",
    "    hs = db['hidden'].detach().cpu().numpy()\n",
    "\n",
    "pca_type = 'full' # full, cell_types\n",
    "pca_target_lst = ['hs', 'Ms'] # hs, 'Ms' \n",
    "if net_params[\"net_type\"] in (\"vanilla\", \"gru\"):\n",
    "    pca_target_lst = ['hs'] # if not dmpn, no M information effectively\n",
    "\n",
    "# using recorded information\n",
    "recordkyle_all, recordkyle_nameall = [], []\n",
    "for test_subtrial in test_trials:\n",
    "    metaepoch = test_subtrial.epochs\n",
    "    periodname = list(metaepoch.keys())\n",
    "    recordkyle, recordkyle_name = [], []\n",
    "    for keyiter in range(len(periodname)):\n",
    "        try:\n",
    "            recordkyle_name.append(periodname[keyiter])\n",
    "            if test_mode_for_all == \"random\":\n",
    "                recordkyle.append(metaepoch[periodname[keyiter]][1])\n",
    "            elif test_mode_for_all == \"random_batch\":\n",
    "                recordkyle.append(list(metaepoch[periodname[keyiter]][1]))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    if test_mode_for_all in (\"random\",):\n",
    "        fillrecordkyle = []\n",
    "        for timestamp in recordkyle:\n",
    "            fillrecordkyle.append([timestamp for _ in range(hs.shape[0])])\n",
    "        recordkyle = fillrecordkyle\n",
    "\n",
    "    recordkyle.insert(0, [0 for _ in range(len(recordkyle[1]))])\n",
    "    recordkyle = np.array(recordkyle).T.tolist()\n",
    "    recordkyle_all.extend(recordkyle)\n",
    "    recordkyle_nameall.append(recordkyle_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f41fdc5-88a2-459a-8ea5-8177aa1a9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sep 30th\n",
    "# This part of code should be adaptive for multitask, which may have different breaks and periods for each task\n",
    "unique_lists = set(tuple(lst) for lst in recordkyle_all)\n",
    "# here select task specific information\n",
    "# which maximally should have length of number of tasks\n",
    "unique_recordkyle_all = [list(lst) for lst in unique_lists]\n",
    "if not task_random_fix:\n",
    "    assert len(unique_recordkyle_all) >= len(rules_dict[hyp_dict['ruleset']])\n",
    "else:\n",
    "    print(\"Test DataSet Random Seed Is Fixed\")\n",
    "\n",
    "all_session_breakdown = []\n",
    "for task_specific_time in unique_recordkyle_all:\n",
    "    session_breakdown = []\n",
    "    for sindex in range(0,len(task_specific_time)-1):\n",
    "        # all sessions should be the same for each task\n",
    "        # but different across tasks\n",
    "        # though the time of when response period starts might be similar across\n",
    "        session_breakdown.append([task_specific_time[sindex], task_specific_time[sindex+1]]) \n",
    "    session_breakdown.append([task_specific_time[0], task_specific_time[-1]])\n",
    "    all_session_breakdown.append(session_breakdown)\n",
    "\n",
    "# break down time\n",
    "all_breaks = []\n",
    "for session_breakdown in all_session_breakdown:\n",
    "    breaks = [cut[1] for cut in session_breakdown[:-1]]\n",
    "    print(f\"Task {all_session_breakdown.index(session_breakdown)}; breaks: {breaks}\")\n",
    "    all_breaks.append(breaks)\n",
    "\n",
    "# for delay-task\n",
    "assert len(all_breaks)\n",
    "response_start = all_breaks[0][-2]\n",
    "stimulus_start = all_breaks[0][0]\n",
    "stimulus_end = all_breaks[0][1]\n",
    "print(f\"response_start: {response_start}\")\n",
    "print(f\"stimulus_start: {stimulus_start}\")\n",
    "print(f\"stimulus_end: {stimulus_end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5adc633-8a73-4e8b-8733-b4ce98482ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages_num = len(Wall_lst) # how many recorded neurons in total\n",
    "break_info = all_breaks[0]\n",
    "\n",
    "input_nums = Ms_orig.shape[-1]\n",
    "batch_nums = Ms_orig.shape[0]\n",
    "neuron_nums = Ms_orig.shape[2]\n",
    "colors = helper.generate_rainbow_colors(Ms_orig.shape[2])\n",
    "\n",
    "def generate_random_orthonormal_matrix(N, num_columns=3):\n",
    "    \"\"\"\n",
    "    generates an N x num_columns random matrix with orthonormal columns.\n",
    "    \"\"\"\n",
    "    random_matrix = np.random.randn(N, num_columns)    \n",
    "    Q, R = np.linalg.qr(random_matrix)    \n",
    "    return Q[:, :num_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6166f5-5166-4a76-bd2c-fa675fc6e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e212e03-6fb4-439b-9fd6-5aefd8a09a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check from equation 2-7\n",
    "def plot_trajectory_by_index(label_index, stage_iter, verbose=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    W_ = Wall_lst[stage_iter][0]\n",
    "    W_output = Woutput_lst[stage_iter]\n",
    "    _, Ms_orig, _, bs, _ = modulation_extraction(db_lst[0][stage_iter], max_seq_len, layer_index) # batch * seq_len * hidden_neuron * input_neuron\n",
    "\n",
    "    if verbose:\n",
    "        figsize1, figsize2 = 3, 6\n",
    "        figexh1, axsexh1 = plt.subplots(3,3,figsize=(figsize2*3,figsize1*3))  \n",
    "        figexh2, axsexh2 = plt.subplots(4,3,figsize=(figsize2*3,figsize1*4))  \n",
    "        figdiff, axsdiff = plt.subplots(1,2,figsize=(4*2,2))\n",
    "\n",
    "    task_middle_dict = {}\n",
    "    task_labels_across_batch = []\n",
    "\n",
    "    saver_shape1 = (3,3)\n",
    "    saver1 = np.empty((test_input.shape[0], saver_shape1[0], saver_shape1[1]), dtype=object)\n",
    "    saver_shape2 = (4,3)\n",
    "    saver2 = np.empty((test_input.shape[0], saver_shape2[0]+1, saver_shape2[1]), dtype=object)\n",
    "    saver2_random = np.empty((test_input.shape[0], saver_shape2[0]+1, saver_shape2[1]), dtype=object) # projection to random space\n",
    "\n",
    "    random_output_Y_lst = [generate_random_orthonormal_matrix(W_output.shape[1]) for _ in range(10)]\n",
    "\n",
    "    for batch_iter in range(test_input.shape[0]):\n",
    "        writeon = 0\n",
    "        labels_for_batch = labels[batch_iter,0]\n",
    "        \n",
    "        if labels_for_batch in label_index: # >=0: for all label; ==0, say, for specific label on the ring (regardless on which task is using)\n",
    "            xx = test_input[batch_iter, :, :].cpu().numpy()[0,6-shift_index:]\n",
    "            which_task = np.where(xx)[0][0] # extract here, will repeat later at different time slices\n",
    "            \n",
    "            if labels_for_batch not in task_middle_dict.keys():\n",
    "                task_middle_dict[which_task] = []\n",
    "                writeon = 1\n",
    "                \n",
    "            x_batch_taskinfo = test_input[batch_iter, :, :][:,6-shift_index:].cpu().numpy()[0,:]\n",
    "            task_specific = np.where(x_batch_taskinfo == 1)[0]\n",
    "            assert len(task_specific) == 1\n",
    "            task_specific = task_specific[0]\n",
    "            \n",
    "            task_labels_across_batch.append(task_specific) # load task information (which task) across batches\n",
    "        \n",
    "            res_eq26, res_eq8, res_eq11 = [], [], []\n",
    "            res_meta = []\n",
    "\n",
    "            for i in range(saver_shape1[0]):\n",
    "                for j in range(saver_shape1[1]):\n",
    "                    saver1[batch_iter, i, j] = np.array([])\n",
    "        \n",
    "            for i in range(saver_shape2[0]+1):\n",
    "                for j in range(saver_shape2[1]):\n",
    "                    saver2[batch_iter, i, j] = np.array([])\n",
    "                    saver2_random[batch_iter, i, j] = np.array([])\n",
    "        \n",
    "            for time_iter in range(test_input.shape[1]):\n",
    "                x = test_input[batch_iter, time_iter, :].cpu().numpy().reshape(-1,1)\n",
    "                \n",
    "                input_length = len(x)\n",
    "        \n",
    "                x_fixon, x_fixoff, x_stimulus, x_task = [np.zeros((input_length, 1)) for _ in range(4)]\n",
    "                # one-hot encoded vector for fixation\n",
    "                x_fixon[0,0] = x[0,0] \n",
    "                # one-hot encoded vector for fixation off (set to dummy if not presented)\n",
    "                x_fixoff[1,0] = x[1,0] if task_params['fixate_off'] else 0\n",
    "                # one-hot encoded vector for stimulus\n",
    "                x_stimulus[2-shift_index:6-shift_index,0] = x[2-shift_index:6-shift_index,0]\n",
    "                # one-hot encoded vector for task\n",
    "                # task (dynamically setting for all element after the 6th elements)\n",
    "                tasks_info = x[6-shift_index:,0]\n",
    "                x_task[6-shift_index:,0] = tasks_info\n",
    "\n",
    "                which_task = np.where(tasks_info)[0][0]\n",
    "                \n",
    "                Mt = Ms_orig[batch_iter, time_iter, :, :] \n",
    "                bt = bs[batch_iter, time_iter, :].reshape(-1,1) # hidden_neuron * 1\n",
    "                \n",
    "                middle =  W_ + W_ * Mt\n",
    "\n",
    "                if time_iter >= response_start + 1 and len(label_index) == 1:\n",
    "                    if writeon:\n",
    "                        task_middle_dict[which_task].append(middle)\n",
    "                \n",
    "                y_fix = W_output[0,:].reshape(1,-1)\n",
    "                Y_resp1 = W_output[1,:].reshape(1,-1)\n",
    "                Y_resp2 = W_output[2,:].reshape(1,-1)\n",
    "\n",
    "                if task_params['fixate_off']:\n",
    "                    allX1 = [x_fixon+x_task, x_fixoff+x_task, x_stimulus+x_fixon+x_task]\n",
    "                else:\n",
    "                    allX1 = [x_fixon+x_task, x_task, x_stimulus+x_fixon+x_task]\n",
    "                allX1name = [\"x_fixon+x_task\", \"x_fixoff+x_task\", \"x_stimulus+x_fixon+x_task\"]\n",
    "                allX2 = [x_fixon, x_fixoff, x_stimulus, x_task]\n",
    "                allX2name = [\"x_fixon\", \"x_fixoff\", \"x_stimulus\", \"x_task\"]\n",
    "                allY = [y_fix, Y_resp1, Y_resp2]\n",
    "                allYname = [\"y_fix\", \"Y_resp1\", \"Y_resp2\"]\n",
    "        \n",
    "                for yiter in range(len(allY)):\n",
    "                    for xiter in range(len(allX1)):\n",
    "                        # res1 = helper.to_unit_vector(allY[yiter]) @ helper.to_unit_vector(middle @ allX1[xiter])\n",
    "                        # print(middle.shape, allX1[xiter].shape)\n",
    "                        step1 = middle @ allX1[xiter] + bt # adjust according to specific bias \n",
    "                        res1 = allY[yiter] @ step1 \n",
    "                        saver1[batch_iter, xiter, yiter] = np.append(saver1[batch_iter, xiter, yiter], res1[0,0])\n",
    "        \n",
    "                for y1 in range(len(allY)):\n",
    "                    for x1 in range(len(allX2)):\n",
    "                        # res2 = helper.to_unit_vector(allY[yiter]) @ helper.to_unit_vector(middle @ allX2[xiter])\n",
    "                        step1 = middle @ allX2[x1]\n",
    "                        res2 = allY[y1] @ step1\n",
    "                        res2_random = [((random_output_Y[:,y1].reshape(1,-1)) @ middle @ allX2[x1])[0,0] \n",
    "                                       for random_output_Y in random_output_Y_lst]\n",
    "                        \n",
    "                        saver2[batch_iter, x1, y1] = np.append(saver2[batch_iter, x1, y1], res2[0,0])\n",
    "                        saver2_random[batch_iter, x1, y1] = np.append(saver2_random[batch_iter, x1, y1], np.mean(res2_random))\n",
    "\n",
    "                # how about bias projection to output\n",
    "                for y_iter2 in range(len(allY)):\n",
    "                    step1 = bt \n",
    "                    res2 = allY[y_iter2] @ step1\n",
    "                    saver2[batch_iter, len(allX2), y_iter2] = np.append(saver2[batch_iter, len(allX2), y_iter2], res2[0,0])\n",
    "\n",
    "            if verbose:\n",
    "                for i in range(saver_shape1[0]):\n",
    "                    for j in range(saver_shape1[1]):\n",
    "                        axsexh1[i,j].plot(saver1[batch_iter,i,j], color=c_vals[labels_for_batch], linestyle=l_vals[task_specific])\n",
    "            \n",
    "                for i in range(saver_shape2[0]):\n",
    "                    for j in range(saver_shape2[1]):            \n",
    "                        axsexh2[i,j].plot(saver2[batch_iter,i,j], color=c_vals[labels_for_batch], linestyle=l_vals[task_specific])\n",
    "        \n",
    "                # # extract fixon-task information explicitly\n",
    "                axsdiff[0].plot(saver2[batch_iter,0,1] + saver2[batch_iter,3,1], color=c_vals[labels_for_batch], linestyle=l_vals[task_specific])\n",
    "                axsdiff[0].plot(saver2_random[batch_iter,0,1] + saver2_random[batch_iter,3,1], color=c_vals_l[labels_for_batch], linestyle=l_vals[task_specific])\n",
    "                \n",
    "                axsdiff[1].plot(saver2[batch_iter,0,2] + saver2[batch_iter,3,2], color=c_vals[labels_for_batch], linestyle=l_vals[task_specific])\n",
    "                axsdiff[1].plot(saver2_random[batch_iter,0,2] + saver2_random[batch_iter,3,2], color=c_vals_l[labels_for_batch], linestyle=l_vals[task_specific])\n",
    "\n",
    "    if verbose:\n",
    "        # plot fixon/task information for one specific stimulus on one figure\n",
    "        # show perfect cancellation until fixon info goes away (during response period)\n",
    "        figpaper, axspaper = plt.subplots(8,1,figsize=(6,figsize1*8))\n",
    "\n",
    "        temp_saver = []\n",
    "\n",
    "        for batch_iter in range(test_input.shape[0]):\n",
    "            labels_for_batch = labels[batch_iter,0]\n",
    "            if labels_for_batch in label_index and labels_for_batch not in temp_saver:\n",
    "                f_fixon, f_task, f_bias = saver2[batch_iter, 0, 1], saver2[batch_iter, 3, 1], saver2[batch_iter, -1, 1]\n",
    "                axspaper[len(temp_saver)].plot(f_fixon, color=c_vals[0], linestyle=l_vals[0], label=\"Fixon\")\n",
    "                axspaper[len(temp_saver)].plot(f_task+f_bias, color=c_vals[1], linestyle=l_vals[1], label=\"Task\")\n",
    "                axspaper[len(temp_saver)].plot(f_fixon+f_task+f_bias, color=c_vals[2], linestyle=l_vals[3], linewidth=3, \\\n",
    "                                                       label=\"Combine\")\n",
    "                axspaper[len(temp_saver)].axhline(0, color=c_vals[3])\n",
    "                axspaper[len(temp_saver)].set_xlabel(\"Timestep\", fontsize=15)\n",
    "                axspaper[len(temp_saver)].set_ylabel(\"Modulation Component\", fontsize=15)\n",
    "\n",
    "                temp_saver.append(labels_for_batch)\n",
    "\n",
    "        for axsp in axspaper:\n",
    "            axsp.legend(loc=\"best\", frameon=True, fontsize=15)\n",
    "            axsp.set_ylim([-2.0, 2.0])\n",
    "        figpaper.tight_layout()   \n",
    "        figpaper.savefig(f\"./onetask/show_seed{seed}.png\", dpi=300)\n",
    "        \n",
    "        for i in range(saver_shape1[0]):\n",
    "            for j in range(saver_shape1[1]):\n",
    "                axsexh1[i,j].set_ylim([-1.2, 1.2])\n",
    "                axsexh1[i,j].set_title(f\"{allX1name[i]} & {allYname[j]}\")\n",
    "        \n",
    "        for i in range(saver_shape2[0]):\n",
    "            for j in range(saver_shape2[1]):\n",
    "                axsexh2[i,j].set_ylim([-1.2, 1.2])\n",
    "                axsexh2[i,j].set_title(f\"{allX2name[i]} & {allYname[j]}\")\n",
    "        \n",
    "        for ax in np.concatenate((axsexh1.flatten(), axsexh2.flatten())):\n",
    "            for breaks in all_breaks:\n",
    "                for bb in breaks:\n",
    "                    ax.axvline(bb, linestyle=\"--\", c=c_vals[all_breaks.index(breaks)])\n",
    "    \n",
    "        label_index_name = \"all\" if len(label_index) == 8 else label_index\n",
    "        \n",
    "        figexh1.suptitle(f\"Exhaustive Search 1 {color_by} at Stage {stage_iter}\")\n",
    "        figexh1.tight_layout()\n",
    "        figexh1.savefig(f\"./onetask/es1_{task_params['fixate_off']}_{network_at_percent}_{label_index_name}_seed{seed}.png\", dpi=300)\n",
    "        \n",
    "        figexh2.suptitle(f\"Exhaustive Search 2 {color_by} Stage {stage_iter}\")\n",
    "        figexh2.tight_layout()\n",
    "        figexh2.savefig(f\"./onetask/es2_{task_params['fixate_off']}_{network_at_percent}_{label_index_name}_seed{seed}.png\", dpi=300)\n",
    "\n",
    "        axsdiff[0].set_title(\"Stimulus 1\")\n",
    "        axsdiff[1].set_title(\"Stimulus 2\")\n",
    "        figdiff.suptitle(f\"Fixon-Task at Stage {stage_iter}\")\n",
    "        figdiff.tight_layout()\n",
    "        figdiff.savefig(f\"./onetask/diff_{task_params['fixate_off']}_{network_at_percent}_{label_index_name}_seed{seed}.png\", dpi=300)\n",
    "\n",
    "    return task_middle_dict if len(label_index) == 1 else {}, task_labels_across_batch, saver2, saver2_random # only do it for single task learnig for clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cbe71-7953-48eb-9f2f-af7d5b3be088",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajectory, all_trajectory_random = [], []\n",
    "for stage_iter in range(stages_num):\n",
    "    task_middle_dict, task_labels_across_batch, save_trajectory, save_trajectory_random = plot_trajectory_by_index(np.unique(labels), \n",
    "                                                                                                                   stage_iter, \n",
    "                                                                                                                   verbose=(stage_iter==stages_num-1))\n",
    "    all_trajectory.append(save_trajectory)\n",
    "    all_trajectory_random.append(save_trajectory_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d7d96a-195a-4b05-adda-ef5af48cc49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trajectory(save_trajectory, save_trajectory_random):\n",
    "    \"\"\"\n",
    "    Analyze trajectories by calculating mean absolute values for fixations and tasks.\n",
    "    \"\"\"\n",
    "    def process_trajectory(trajectory, ind=False):\n",
    "        results = []\n",
    "        for batch in trajectory:\n",
    "            stim1_fixon = batch[0, 1][stimulus_start:response_start]\n",
    "            stim1_task = batch[3, 1][stimulus_start:response_start]\n",
    "            if ind: \n",
    "                bias = batch[4, 1][stimulus_start:response_start]\n",
    "            else:\n",
    "                bias = np.zeros_like(stim1_fixon.shape)\n",
    "                \n",
    "            results.append([np.mean(np.abs(stim1_fixon + stim1_task + bias)), np.mean(np.abs(stim1_fixon)), np.mean(np.abs(stim1_task))])\n",
    "        return np.array(results)\n",
    "    \n",
    "    # Process both trajectories\n",
    "    result = process_trajectory(save_trajectory, True)\n",
    "    result_random = process_trajectory(save_trajectory_random)\n",
    "    \n",
    "    # Return the mean of the computed values\n",
    "    return np.mean(result[:, 0]), np.mean(result[:, 1]), np.mean(result[:,2]), np.mean(result_random[:, 0]), np.mean(result_random[:, 1]), np.mean(result_random[:, 2])\n",
    "\n",
    "fixon_task_diff = np.array([analyze_trajectory(all_trajectory[i], all_trajectory_random[i]) for i in range(len(all_trajectory_random))])\n",
    "\n",
    "figfixontaskcancel, axsfixontaskcancel = plt.subplots(figsize=(6,3))\n",
    "axsfixontaskcancel.plot(counter_lst, fixon_task_diff[:,0], \"-o\", c=c_vals[0], \n",
    "                        label=r\"$\\text{|Fix - Task|}$\")\n",
    "axsfixontaskcancel.plot(counter_lst, fixon_task_diff[:,1], \"-o\", c=c_vals[1], \n",
    "                        label=r\"$\\text{|Fix|}$\")\n",
    "axsfixontaskcancel.plot(counter_lst, fixon_task_diff[:,2], \"-o\", c=c_vals[2], \n",
    "                        label=r\"$\\text{|Task|}$\")\n",
    "# axsfixontaskcancel[0].plot(fixon_task_diff[:,3], \"-o\", c=c_vals_l[0], label=\"abs(fixon-task) random\")\n",
    "# axsfixontaskcancel[0].plot(fixon_task_diff[:,4], \"-o\", c=c_vals_l[1], label=\"abs(fixon) random\")\n",
    "# axsfixontaskcancel[0].plot(fixon_task_diff[:,5], \"-o\", c=c_vals_l[2], label=\"abs(task) random\")\n",
    "axsfixontaskcancel.legend(loc=\"best\", fontsize=15, frameon=True)\n",
    "axsfixontaskcancel.set_ylabel(\"Magnitude Projection \\nMagnitude\", fontsize=15)\n",
    "# axsfixontaskcancel.set_title(\"Average Cancellation Effect Before Response Period\")\n",
    "\n",
    "axsfixontaskcancel.set_xlabel(\"# Dataset\", fontsize=15)\n",
    "axsfixontaskcancel.set_xscale(\"log\")\n",
    "axsfixontaskcancel.tick_params(axis='y', labelsize=12)\n",
    "axsfixontaskcancel.tick_params(axis='x', labelsize=12)\n",
    "figfixontaskcancel.tight_layout()\n",
    "figfixontaskcancel.savefig(f\"./onetask/cancel_seed{seed}.png\", dpi=300)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6,3))  # Create a new figure\n",
    "\n",
    "ax1.plot(counter_lst, loss_lst, \"-o\", c=c_vals[0])\n",
    "ax1.set_ylabel(\"MSE Loss\", color=c_vals[0], fontsize=15)\n",
    "ax1.tick_params(axis='y', colors=c_vals[0], labelsize=12)\n",
    "ax1.set_yscale(\"log\")  # Keep log scale for loss\n",
    "ax1.set_xlabel(\"Counter\")\n",
    "\n",
    "# Create a second y-axis for accuracy (right)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(counter_lst, acc_lst, \"-o\", c=c_vals[1])\n",
    "ax2.axhline(y=1/8, linestyle=\"--\", label=\"By Chance\")\n",
    "ax2.set_ylabel(\"Accuracy\", color=c_vals[1], fontsize=15)\n",
    "ax2.tick_params(axis='y', colors=c_vals[1], labelsize=12)\n",
    "ax2.legend(loc='best', frameon=True, fontsize=15)\n",
    "\n",
    "ax1.set_xlabel(\"# Dataset\", fontsize=15)\n",
    "ax1.tick_params(axis='x', labelsize=12)\n",
    "ax1.set_xscale(\"log\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"./onetask/loss_acc_seed{seed}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c1aa8-307f-4c84-9255-4e9d7cdc75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "modulation_dict_diff_lst = []\n",
    "modulation_dict_lst = []\n",
    "hidden_output_dict_lst = []\n",
    "hidden_dict_lst = []\n",
    "hidden_all_dict_lst = []\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=stages_num,\n",
    "    specs=[[{'type': 'scatter3d'}] * stages_num],\n",
    "    subplot_titles=[f\"Stage {i+1}\" for i in range(stages_num)]  # Add titles for each subplot\n",
    ")\n",
    "\n",
    "camera = dict(\n",
    "    eye=dict(x=1.25, y=1.25, z=1.25),  # Position of the camera\n",
    "    up=dict(x=0, y=0, z=1),            # Orientation of the camera\n",
    "    center=dict(x=0, y=0, z=0),        # Focal point of the camera\n",
    ")\n",
    "\n",
    "for stage_iter in range(stages_num):\n",
    "    Woutput = Woutput_lst[stage_iter]\n",
    "    _, Ms_orig, hs, bs, _ = modulation_extraction(db_lst[0][stage_iter], max_seq_len, layer_index)\n",
    "    \n",
    "    hs_stimulus = hs[:,stimulus_start:stimulus_end,:]\n",
    "\n",
    "    Ms_fix = Ms_orig[:,:stimulus_start,:,:]\n",
    "    Ms_stimulus = Ms_orig[:,stimulus_start:stimulus_end,:,:]\n",
    "    Ms_delay = Ms_orig[:,stimulus_end:response_start,:,:]\n",
    "    Ms_response = Ms_orig[:,response_start:,:,:]\n",
    "    \n",
    "    Ms_all = [Ms_fix, Ms_stimulus, Ms_delay, Ms_response]\n",
    "\n",
    "    modulation_diff_dict, modulation_dict, hidden_output_dict, hidden_dict, hidden_all_dict = {}, {}, {}, {}, {}\n",
    "    \n",
    "    for batch_iter in range(batch_nums):\n",
    "        hs_stimulus_batch = hs_stimulus[batch_iter,:,:]\n",
    "        hs_stimulus_batch_output = hs_stimulus_batch @ Woutput.T\n",
    "\n",
    "        trace = go.Scatter3d(\n",
    "            x=hs_stimulus_batch_output[:, 0],\n",
    "            y=hs_stimulus_batch_output[:, 1],\n",
    "            z=hs_stimulus_batch_output[:, 2],\n",
    "            mode='lines+markers', \n",
    "            line=dict(color=c_vals[labels[batch_iter][0]], width=2),  \n",
    "            marker=dict(size=5, symbol='circle'), \n",
    "            name=f\"Batch {batch_iter} - Stage {stage_iter}\",\n",
    "            showlegend=False \n",
    "        )\n",
    "        fig.add_trace(trace, row=1, col=stage_iter + 1)\n",
    "        \n",
    "        # modulation change for different periods (end - start)\n",
    "        Ms_fixon = [Ms_[batch_iter,-1,:,0] - Ms_[batch_iter,0,:,0] for Ms_ in Ms_all]\n",
    "        Ms_stimulus_task = Ms_stimulus[batch_iter,-1,:,-1] - Ms_stimulus[batch_iter,0,:,-1]\n",
    "        \n",
    "        modulation_diff_dict[labels[batch_iter,0]] = Ms_fixon # change of modulation on fixon during stimulus period\n",
    "        modulation_dict[labels[batch_iter,0]] =  Ms_stimulus[batch_iter,-1,:,0]\n",
    "        hidden_output_dict[labels[batch_iter,0]] = hs_stimulus_batch_output\n",
    "        hidden_dict[labels[batch_iter,0]] = hs_stimulus_batch[-1,:]\n",
    "        hidden_all_dict[labels[batch_iter,0]] = hs_stimulus_batch\n",
    "\n",
    "    modulation_dict_diff_lst.append(modulation_diff_dict)\n",
    "    modulation_dict_lst.append(modulation_dict)\n",
    "    hidden_output_dict_lst.append(hidden_output_dict)\n",
    "    hidden_dict_lst.append(hidden_dict)\n",
    "    hidden_all_dict_lst.append(hidden_all_dict)\n",
    "\n",
    "for stage_iter in range(stages_num):\n",
    "    fig.update_layout(\n",
    "        **{\n",
    "            f\"scene{stage_iter + 1}\": dict(\n",
    "                xaxis=dict(range=[-1.3, 1.3], title=\"X\"),\n",
    "                yaxis=dict(range=[-1.3, 1.3], title=\"Y\"),\n",
    "                zaxis=dict(range=[-1.3, 1.3], title=\"Z\"),\n",
    "                aspectmode='cube',  \n",
    "                camera=camera,       \n",
    "                domain=dict(\n",
    "                    x=[stage_iter / stages_num, (stage_iter + 1) / stages_num - 0.02],  \n",
    "                    y=[0, 1]  \n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"3D Interactive Plot for Different Stages\",\n",
    "    height=600, \n",
    "    width=600 * stages_num, \n",
    "    margin=dict(l=10, r=10, t=50, b=10),  \n",
    ")\n",
    "\n",
    "output_file = \"./save/3d_interactive_plot_compact.html\"\n",
    "# fig.write_html(output_file)\n",
    "\n",
    "print(f\"Plot saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb427a04-1279-4f63-867b-87dee94a7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "modulation_change_stage, m_corr_stage, h_corr_stage = [[],[],[],[]], [], []\n",
    "fig_hc, axs_hc = plt.subplots(2,1,figsize=(6,3*2))\n",
    "\n",
    "def binarize(arr, threshold):\n",
    "    \"\"\"\"\"\"\n",
    "    return (np.abs(arr) > threshold).astype(int)\n",
    "\n",
    "def normalized_participation_ratio(cov_matrix):\n",
    "    \"\"\"\"\"\"\n",
    "    eigenvalues = np.linalg.eigvalsh(cov_matrix)  \n",
    "    sum_eigen = np.sum(eigenvalues)\n",
    "    sum_eigen_sq = np.sum(eigenvalues ** 2)    \n",
    "    N = len(eigenvalues)\n",
    "    npr = (sum_eigen ** 2) / (N * sum_eigen_sq)\n",
    "    return npr\n",
    "    \n",
    "for i in range(stages_num):\n",
    "    def analyze_hm_change(lst, index=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        md = lst[i]\n",
    "        if index is None: \n",
    "            md_m = [np.array(value) for value in md.values()]\n",
    "        else:\n",
    "            md_m = [np.array(value[index]) for value in md.values()]\n",
    "        md_m = np.column_stack(md_m)\n",
    "        md_m = md_m.T # num_stimulus * hidden_size\n",
    "        mc_stage = list(np.mean(np.abs(md_m), axis=1))\n",
    "        synptic_corr = cosine_similarity(md_m)     \n",
    "        mean_corr = np.nanmean(np.triu(synptic_corr))\n",
    "        return mean_corr, mc_stage, md_m\n",
    "        \n",
    "    m_mean_corr, _, md_m = analyze_hm_change(modulation_dict_lst)\n",
    "    h_mean_corr, _, md_h = analyze_hm_change(hidden_dict_lst)\n",
    "        \n",
    "    m_corr_stage.append(m_mean_corr)\n",
    "    h_corr_stage.append(h_mean_corr)\n",
    "    md_m_diff_stim = None\n",
    "    for p in range(4):\n",
    "        _, mc_stage, md_m_diff = analyze_hm_change(modulation_dict_diff_lst, p)\n",
    "        if p == 1:\n",
    "            md_m_diff_stim = md_m_diff\n",
    "        elif p == 3:\n",
    "            md_m_diff_response = md_m_diff\n",
    "        modulation_change_stage[p].append(mc_stage)\n",
    "\n",
    "    if i == stages_num - 1:\n",
    "        sns.heatmap(md_m_diff_stim, ax=axs_hc[0], cmap=\"coolwarm\")\n",
    "        sns.heatmap(md_m_diff_response, ax=axs_hc[1], cmap=\"coolwarm\")\n",
    "        for ax_hc in axs_hc: \n",
    "            ax_hc.set_xticks([])\n",
    "            ax_hc.set_yticks([])\n",
    "            ax_hc.set_xlabel(\"Hidden\", fontsize=15)\n",
    "            ax_hc.set_ylabel(\"Stimuli\", fontsize=15)\n",
    "        fig_hc.tight_layout()\n",
    "        fig_hc.savefig(f\"./onetask/modulation_heatmap_seed{seed}.png\", dpi=300)\n",
    "\n",
    "modulation_change_stage = np.array(modulation_change_stage)\n",
    "period_names = [\"Fixation\", \"Stimulus\", \"Delay\", \"Response\"]\n",
    "\n",
    "figmc,axsmc = plt.subplots(3,1,figsize=(6,3*3))\n",
    "for i in range(4):\n",
    "    mcs = modulation_change_stage[i]\n",
    "    print(mcs.shape)\n",
    "    axsmc[0].plot(counter_lst, np.mean(mcs, axis=1), \"-o\", c=c_vals[i], label=period_names[i])\n",
    "    axsmc[0].fill_between(counter_lst, np.mean(mcs, axis=1) - np.std(mcs, axis=1), \\\n",
    "                                       np.mean(mcs, axis=1) + np.std(mcs, axis=1), color=c_vals_l[i])\n",
    "axsmc[0].set_ylabel(\"Change of Modulation\", fontsize=15)\n",
    "axsmc[0].legend(loc=\"best\", frameon=True, fontsize=15)\n",
    "axsmc[1].plot(counter_lst, m_corr_stage/m_corr_stage[0], \"-o\")\n",
    "axsmc[1].set_ylabel(\"Average Synaptic Correlation \\nbetween Stimulus\", fontsize=15)\n",
    "axsmc[2].plot(counter_lst, h_corr_stage/h_corr_stage[0], \"-o\")\n",
    "axsmc[2].set_ylabel(\"Postsynaptic Activity Correlation \\nbetween Stimulus\", fontsize=15)\n",
    "\n",
    "\n",
    "def save_dict_with_count_npz(directory, data_dict, it=\"\"):\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Count existing files in the directory\n",
    "    file_count = len([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])\n",
    "\n",
    "    # Generate filename based on file count\n",
    "    filename = os.path.join(directory, f\"{it}{file_count}.npz\")\n",
    "\n",
    "    # Save dictionary as an NPZ file\n",
    "    np.savez(filename, **data_dict)\n",
    "\n",
    "    print(f\"Dictionary saved as: {filename}\")\n",
    "\n",
    "\n",
    "data_json = {\"counter_lst\": counter_lst, \"m_corr_stage\": m_corr_stage/m_corr_stage[0], \"h_corr_stage\": h_corr_stage/h_corr_stage[0]}\n",
    "save_dict_with_count_npz(\"./onetask_data\", data_json, it=\"corr\")\n",
    "\n",
    "for ax in axsmc:\n",
    "    ax.set_xlabel(\"# Dataset\", fontsize=15)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.tick_params(axis=\"y\", labelsize=12)\n",
    "    ax.tick_params(axis=\"x\", labelsize=12)\n",
    "    \n",
    "figmc.tight_layout()\n",
    "figmc.savefig(f\"./onetask/modulation_change_seed{seed}.png\", dpi=300)\n",
    "\n",
    "def traj_length(array):\n",
    "    \"\"\"\"\"\"\n",
    "    diffs = np.diff(array, axis=0)  \n",
    "    return np.sum(np.linalg.norm(diffs, axis=1))\n",
    "\n",
    "hidden_length_all = []\n",
    "for stage_iter in range(stages_num):\n",
    "    hidden_stage = hidden_output_dict_lst[stage_iter] \n",
    "    hidden_stage = {k: hidden_stage[k] for k in sorted(hidden_stage.keys())}\n",
    "    hidden_length = [traj_length(arr) for arr in hidden_stage.values()]    \n",
    "    hidden_length_all.append(hidden_length)\n",
    "    \n",
    "hidden_length_all = np.array(hidden_length_all)\n",
    "figt, axst = plt.subplots(figsize=(6,3))\n",
    "for i in range(hidden_length_all.shape[1]):\n",
    "    axst.plot(counter_lst, hidden_length_all[:,i], \"-o\", c=c_vals[i])\n",
    "axst.set_xlabel(\"# Dataset\", fontsize=15)\n",
    "axst.set_xscale(\"log\")\n",
    "axst.set_ylabel(\"Length of Hidden \\nState Trajectory\", fontsize=15)\n",
    "axst.tick_params(axis=\"y\", labelsize=12)\n",
    "axst.tick_params(axis=\"x\", labelsize=12)\n",
    "figt.tight_layout()\n",
    "figt.savefig(f\"./onetask/length_hidden_state_seed{seed}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b7833-7825-487f-9a02-f5938cbecbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os \n",
    "\n",
    "def load_all_npz_files(directory):\n",
    "    npz_files = sorted(glob.glob(os.path.join(directory, \"*.npz\")))\n",
    "\n",
    "    data_list = []\n",
    "    for file in npz_files:\n",
    "        data = np.load(file)  \n",
    "        data_list.append({key: data[key] for key in data.files})  \n",
    "\n",
    "        print(f\"Loaded: {file}\") \n",
    "\n",
    "    return data_list\n",
    "\n",
    "plotall = True \n",
    "if plotall:\n",
    "    directory = \"./onetask_data\"\n",
    "    all_data = load_all_npz_files(directory)\n",
    "    counter_lst_all, m_corr_all, h_corr_all = [], [], []\n",
    "    for i, data in enumerate(all_data):\n",
    "        counter_lst_all.append(data[\"counter_lst\"])\n",
    "        m_corr_all.append(data[\"m_corr_stage\"])\n",
    "        h_corr_all.append(data[\"h_corr_stage\"])\n",
    "\n",
    "    counter_lst_all = np.array(counter_lst_all)\n",
    "    m_corr_all = np.array(m_corr_all)\n",
    "    h_corr_all = np.array(h_corr_all)\n",
    "\n",
    "    mean_counter = np.mean(counter_lst_all, axis=0)\n",
    "    mean_m_corr = np.mean(m_corr_all, axis=0)\n",
    "    std_m_corr = np.std(m_corr_all, axis=0)\n",
    "    \n",
    "    mean_h_corr = np.mean(h_corr_all, axis=0)\n",
    "    std_h_corr = np.std(h_corr_all, axis=0)\n",
    "    \n",
    "    figmcall, axsmcall = plt.subplots(2,1,figsize=(6,3*2))\n",
    "    axsmcall[0].plot(mean_counter, mean_m_corr, \"-o\", label=\"Mean m_corr\", color=c_vals[0])\n",
    "    axsmcall[0].fill_between(mean_counter, mean_m_corr - std_m_corr, mean_m_corr + std_m_corr, \n",
    "                             color=c_vals_l[0], alpha=0.2)\n",
    "    axsmcall[0].set_ylabel(\"Cos of Modulation\", fontsize=15)\n",
    "    axsmcall[1].plot(mean_counter, mean_h_corr, \"-o\", label=\"Mean h_corr\", color=c_vals[0])\n",
    "    axsmcall[1].fill_between(mean_counter, mean_h_corr - std_h_corr, mean_h_corr + std_h_corr, \n",
    "                             color=c_vals_l[0], alpha=0.2)\n",
    "    axsmcall[1].set_ylabel(\"Cos of Hidden Activity\", fontsize=15)\n",
    "    for ax in axsmcall:\n",
    "        ax.set_xlabel(\"# Dataset\", fontsize=15)\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.tick_params(axis=\"y\", labelsize=12)\n",
    "        ax.tick_params(axis=\"x\", labelsize=12)\n",
    "    figmcall.tight_layout()\n",
    "    figmcall.savefig(f\"./onetask/modulation_analysis_during_learning_seed{seed}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c697459a-40b7-4410-b4de-e651462f45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = Wall_lst[-1][0]\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffac89-2d1b-460f-a42d-a782c3940f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixon_task_projoutput = []\n",
    "for stage_iter in range(stages_num):\n",
    "    W = Wall_lst[stage_iter][0]\n",
    "    W_output = Woutput_lst[stage_iter]\n",
    "\n",
    "    _, Ms_orig, _, bs, _ = modulation_extraction(db_lst[0][stage_iter], max_seq_len, layer_index) # batch * seq_len * hidden_neuron * input_neuron\n",
    "    bias = np.mean(bs, axis=0)\n",
    "\n",
    "    W_output_random_lst = [generate_random_orthonormal_matrix(W_output.shape[1]) for _ in range(10)]\n",
    "    W_fixon = W[:,0].reshape(-1,1)\n",
    "    W_task = W[:,6-shift_index].reshape(-1,1)\n",
    "    \n",
    "    fixon_output, task_output = W_output[1:,:] @ W_fixon, W_output[1:,:] @ W_task\n",
    "    bias_output = np.mean(bias @ (W_output[1:,:].T), axis=0)\n",
    "    fixon_proj_output_norm1 = fixon_output[0] + bias_output[0]\n",
    "    task_proj_output_norm1 = task_output[0] \n",
    "    fixon_proj_output_norm2 = fixon_output[1] + bias_output[1]\n",
    "    task_proj_output_norm2 = task_output[1] \n",
    "\n",
    "    fixon_output_random, task_output_random = [(W_output_random.T @ W_fixon) for W_output_random in W_output_random_lst], [(W_output_random.T @ W_task) for W_output_random in W_output_random_lst]\n",
    "    fixon_proj_output_norm_random = np.mean([np.sum(fixon_output_r) for fixon_output_r in fixon_output_random])\n",
    "    task_proj_output_norm_random = np.mean([np.sum(task_output_r) for task_output_r in task_output_random])\n",
    "    \n",
    "    fixon_task_projoutput.append([fixon_proj_output_norm1[0], task_proj_output_norm1[0], \n",
    "                                  fixon_proj_output_norm2[0], task_proj_output_norm2[0], \n",
    "                                  fixon_proj_output_norm_random, task_proj_output_norm_random]\n",
    "    )\n",
    "\n",
    "fixon_task_projoutput = np.array(fixon_task_projoutput)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,3))\n",
    "ax.plot(counter_lst, fixon_task_projoutput[:, 0], marker=\"o\", color=c_vals[0], \n",
    "        linestyle=l_vals[0], label=\"fixon proj output1\")\n",
    "ax.plot(counter_lst, fixon_task_projoutput[:, 1], marker=\"o\", color=c_vals[0], \n",
    "        linestyle=l_vals[1], label=\"task proj output1\")\n",
    "ax.plot(counter_lst, fixon_task_projoutput[:, 0]+fixon_task_projoutput[:, 1], marker=\"o\", color=c_vals[1], \n",
    "        linestyle=l_vals[2], linewidth=1, label=\"fixon/task sum output1\")\n",
    "ax.axhline(0, color=c_vals[1], linestyle=l_vals[2])\n",
    "\n",
    "# ax.plot(counter_lst, fixon_task_projoutput[:, 2], \"-o\", color=c_vals[1], linestyle=l_vals[0], label=\"fixon proj output2\")\n",
    "# ax.plot(counter_lst, fixon_task_projoutput[:, 3], \"-o\", color=c_vals[1], linestyle=l_vals[1], label=\"task proj output2\")\n",
    "# ax.plot(counter_lst, fixon_task_projoutput[:, 2]+fixon_task_projoutput[:, 3], \"-o\", color=c_vals[1], linestyle=l_vals[2], linewidth=3, label=\"fixon/task sum output2\")\n",
    "# ax.plot(counter_lst, fixon_task_projoutput[:,2], \"-o\", c=c_vals_l[0], label=\"fixon proj output random\")\n",
    "# ax.plot(counter_lst, fixon_task_projoutput[:,3], \"-o\",c=c_vals_l[1], label=\"task proj output random\")\n",
    "ax.legend(loc=\"lower left\", fontsize=15, frameon=True)    \n",
    "ax.set_xlabel(\"# Dataset\", fontsize=15)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_ylabel(\"Weight Component \\nProjection\", fontsize=15)\n",
    "ax.tick_params(axis=\"y\", labelsize=12)\n",
    "ax.tick_params(axis=\"x\", labelsize=12)\n",
    "fig.savefig(f\"./onetask/w_to_output_seed{seed}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3d781-4921-407a-a0e6-570f200cd040",
   "metadata": {},
   "outputs": [],
   "source": [
    "fighs, axshs = plt.subplots(3,1,figsize=(6*1,3*3),squeeze=False)\n",
    "\n",
    "start_stage = stages_num-1\n",
    "for stage_iter in range(start_stage, stages_num):\n",
    "    PCA_downsample = 3\n",
    "    _, Ms_orig, hs, bs, _ = modulation_extraction(db_lst[0][stage_iter], max_seq_len, layer_index)\n",
    "\n",
    "    pca = PCA(n_components = PCA_downsample)\n",
    "\n",
    "    Ms_end_of_stimulus = Ms_orig[:,stimulus_end:stimulus_end+1,:,:]\n",
    "    Ms_end_of_stimulus_flattened = Ms_end_of_stimulus.reshape(Ms_end_of_stimulus.shape[0] * Ms_end_of_stimulus.shape[1] * Ms_end_of_stimulus.shape[3], \n",
    "                                                              Ms_end_of_stimulus.shape[2])\n",
    "    pca.fit(Ms_end_of_stimulus_flattened)\n",
    "    Ms_flattened = Ms_orig.reshape(Ms_orig.shape[0] * Ms_orig.shape[1] * Ms_orig.shape[3], Ms_orig.shape[2])\n",
    "    projected_data = pca.transform(Ms_flattened)\n",
    "    Ms_reconstructed = projected_data.reshape(Ms_orig.shape[0], Ms_orig.shape[1], Ms_orig.shape[3], PCA_downsample)\n",
    "\n",
    "    lowd_data_lst = [Ms_reconstructed[:,:,0,:]] # for instance, modulation of fixon\n",
    "    \n",
    "    for i in range(hs.shape[0]):\n",
    "        for dd in range(len(lowd_data_lst)):\n",
    "            lowd_data = lowd_data_lst[dd]\n",
    "            data_batch = lowd_data[i,:,:]\n",
    "\n",
    "            col = stage_iter - start_stage\n",
    "            axs = axshs[:, col]\n",
    "            \n",
    "            # (row, xPC, yPC) with 0-based PC indices: PC1->0, PC2->1, PC3->2\n",
    "            pairs = [\n",
    "                (0, 0, 1),  # (PC1, PC2)\n",
    "                (1, 0, 2),  # (PC1, PC3)\n",
    "                (2, 1, 2),  # (PC2, PC3)\n",
    "            ]\n",
    "            \n",
    "            color = c_vals[labels[i, 0]]\n",
    "            \n",
    "            # Plot (PC1,PC2) in 3 segments (as you had)\n",
    "            segments_12 = [\n",
    "                (slice(stimulus_start, stimulus_end), markers_vals[dd],      \"-\"),\n",
    "                (slice(stimulus_end, response_start), markers_vals[dd + 1],  \"-.\"),\n",
    "                (slice(response_start, None),         markers_vals[dd + 2],  \"--\"),\n",
    "            ]\n",
    "            \n",
    "            row, xpc, ypc = pairs[0]\n",
    "            for sl, mk, ml in segments_12:\n",
    "                axs[row].plot(data_batch[sl, xpc], data_batch[sl, ypc],\n",
    "                              marker=mk, markersize=4, c=color, alpha=0.5, linestyle=ml)\n",
    "            \n",
    "            # Plot the other two pairs in the stimulus segment only (as you had)\n",
    "            for row, xpc, ypc in pairs[1:]:\n",
    "                axs[row].plot(data_batch[stimulus_start:stimulus_end, xpc],\n",
    "                              data_batch[stimulus_start:stimulus_end, ypc],\n",
    "                              marker=markers_vals[dd], markersize=3, c=color, alpha=0.5)\n",
    "            \n",
    "            # Labels\n",
    "            for row, xpc, ypc in pairs:\n",
    "                axs[row].set_xlabel(f\"PC {xpc+1}\", fontsize=15)\n",
    "                axs[row].set_ylabel(f\"PC {ypc+1}\", fontsize=15)\n",
    "\n",
    "\n",
    "fighs.tight_layout()\n",
    "fighs.savefig(f\"./onetask/m_pca_seed{seed}.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d992cd9-2415-4322-8351-2da5056d05af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mpn)",
   "language": "python",
   "name": "mpn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
